---------------------------------------
Begin Slurm Prolog: Nov-05-2024 08:47:57
Job ID:    911902
User ID:   zyahn3
Account:   scs
Job name:  TOG_Plus_R50
Partition: coc-gpu
---------------------------------------
/storage/ice1/5/9/zyahn3/TOG_plus/detrex/detrex/layers/dcn_v3.py:23: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @custom_fwd
/storage/ice1/5/9/zyahn3/TOG_plus/detrex/detrex/layers/dcn_v3.py:52: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  @custom_bwd
[11/05 08:48:21 detectron2]: Rank of current process: 0. World size: 1
[11/05 08:48:23 detectron2]: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:12:24) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/storage/ice1/5/9/zyahn3/TOG_plus/detrex/detectron2/detectron2
Compiler                         GCC 12.3
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/hice1/zyahn3/.conda/envs/TOG_test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA A100 80GB PCIe (arch=8.0)
Driver version                   555.42.02
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/hice1/zyahn3/.conda/envs/TOG_test/lib/python3.12/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.10.0
-------------------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[11/05 08:48:23 detectron2]: Command line arguments: Namespace(config_file='detrex/projects/dino/configs/dino-resnet/dino_r50_4scale_12ep.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:53103', opts=['train.init_checkpoint=model_files/dino_r50_4scale.pth', 'attack=none', 'attack_mode=none', 'sample=1.0', 'save_attack=0.0', 'save_dir=datasets/blackbox/dino_r50_vanishing/', 'load_attack=0.0', 'load_dir=datasets/blackbox/focalnet_vanishing/'])
[11/05 08:48:24 detectron2]: Contents of args.config_file=detrex/projects/dino/configs/dino-resnet/dino_r50_4scale_12ep.py:
[38;5;204mfrom[39m[38;5;15m [39m[38;5;15mdetrex[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;204mimport[39m[38;5;15m [39m[38;5;15mget_config[39m
[38;5;204mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mdino_r50[39m[38;5;15m [39m[38;5;204mimport[39m[38;5;15m [39m[38;5;15mmodel[39m

[38;5;245m# get default config[39m
[38;5;15mdataloader[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/data/coco_detr.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;204m.[39m[38;5;15mdataloader[39m
[38;5;15moptimizer[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/optim.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;204m.[39m[38;5;15mAdamW[39m
[38;5;15mlr_multiplier[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/coco_schedule.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;204m.[39m[38;5;15mlr_multiplier_12ep[39m
[38;5;15mtrain[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/train.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;204m.[39m[38;5;15mtrain[39m

[38;5;245m# modify training config[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15minit_checkpoint[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m[38;5;186m"[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./output/dino_r50_4scale_12ep[39m[38;5;186m"[39m

[38;5;245m# max training iterations[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mmax_iter[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15meval_period[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mlog_period[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mcheckpointer[39m[38;5;204m.[39m[38;5;15mperiod[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m5000[39m

[38;5;245m# gradient clipping for training[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mclip_grad[39m[38;5;204m.[39m[38;5;15menabled[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mclip_grad[39m[38;5;204m.[39m[38;5;15mparams[39m[38;5;204m.[39m[38;5;15mmax_norm[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mclip_grad[39m[38;5;204m.[39m[38;5;15mparams[39m[38;5;204m.[39m[38;5;15mnorm_type[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;245m# set training devices[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcuda[39m[38;5;186m"[39m
[38;5;15mmodel[39m[38;5;204m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mdevice[39m

[38;5;245m# modify optimizer config[39m
[38;5;15moptimizer[39m[38;5;204m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;204m.[39m[38;5;15mbetas[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15m([39m[38;5;141m0.9[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m0.999[39m[38;5;15m)[39m
[38;5;15moptimizer[39m[38;5;204m.[39m[38;5;15mweight_decay[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;204m.[39m[38;5;15mparams[39m[38;5;204m.[39m[38;5;15mlr_factor_func[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;81mlambda[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m[38;5;15m [39m[38;5;81mif[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbackbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;204min[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m [39m[38;5;81melse[39m[38;5;15m [39m[38;5;141m1[39m

[38;5;245m# modify dataloader config[39m
[38;5;15mdataloader[39m[38;5;204m.[39m[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mnum_workers[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m16[39m

[38;5;245m# please notice that this is total batch size.[39m
[38;5;245m# surpose you're using 4 gpus for training and the batch size for[39m
[38;5;245m# each gpu is 16/4 = 4[39m
[38;5;15mdataloader[39m[38;5;204m.[39m[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mtotal_batch_size[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m16[39m

[38;5;245m# dump the testing results into output_dir for visualization[39m
[38;5;15mdataloader[39m[38;5;204m.[39m[38;5;15mevaluator[39m[38;5;204m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15moutput_dir[39m

[38;5;15mattack[39m[38;5;204m=[39m[38;5;81mNone[39m
[38;5;15mattack_mode[39m[38;5;204m=[39m[38;5;81mNone[39m
[38;5;15msample[39m[38;5;204m=[39m[38;5;141m1.0[39m
[38;5;15msave_attack[39m[38;5;204m=[39m[38;5;81mNone[39m
[38;5;15msave_dir[39m[38;5;204m=[39m[38;5;81mNone[39m

WARNING [11/05 08:48:24 d2.config.lazy]: The config contains objects that cannot serialize to a valid yaml. ./output/dino_r50_4scale_12ep/config.yaml is human-readable but cannot be loaded.
WARNING [11/05 08:48:24 d2.config.lazy]: Config is saved using cloudpickle at ./output/dino_r50_4scale_12ep/config.yaml.pkl.
[11/05 08:48:24 detectron2]: Full config saved to ./output/dino_r50_4scale_12ep/config.yaml
[11/05 08:48:24 d2.utils.env]: Using a generated random seed 28145397
[11/05 08:48:28 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from model_files/dino_r50_4scale.pth ...
[11/05 08:48:28 fvcore.common.checkpoint]: [Checkpointer] Loading from model_files/dino_r50_4scale.pth ...
/home/hice1/zyahn3/.conda/envs/TOG_test/lib/python3.12/site-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=torch.device("cpu"))
[11/05 08:48:31 detectron2]: Run evaluation under eval-only mode
[11/05 08:48:31 detectron2]: Run evaluation without EMA.
[11/05 08:48:32 d2.data.datasets.coco]: Loaded 5000 images in COCO format from /home/hice1/zyahn3/scratch/TOG_plus/datasets/coco/annotations/instances_val2017.json
[11/05 08:48:32 d2.data.build]: Distribution of instances among all 80 categories:
|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |
[11/05 08:48:32 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[11/05 08:48:32 d2.data.common]: Serializing 5000 elements to byte tensors and concatenating them all ...
[11/05 08:48:32 d2.data.common]: Serialized dataset takes 19.27 MiB
[11/05 08:48:33 d2.evaluation.evaluator]: Start inference on 5000 batches
Doing attack: None
/home/hice1/zyahn3/.conda/envs/TOG_test/lib/python3.12/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1724789220573/work/aten/src/ATen/native/TensorShape.cpp:3609.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[11/05 08:48:49 d2.evaluation.evaluator]: Inference done 1/5000. Dataloading: 1.4860 s/iter. Inference: 15.0442 s/iter. Eval: 0.0809 s/iter. Total: 16.6123 s/iter. ETA=23:04:04
[11/05 08:48:54 d2.evaluation.evaluator]: Inference done 57/5000. Dataloading: 0.0015 s/iter. Inference: 0.0861 s/iter. Eval: 0.0003 s/iter. Total: 0.0879 s/iter. ETA=0:07:14
[11/05 08:48:59 d2.evaluation.evaluator]: Inference done 122/5000. Dataloading: 0.0016 s/iter. Inference: 0.0800 s/iter. Eval: 0.0003 s/iter. Total: 0.0820 s/iter. ETA=0:06:40
[11/05 08:49:04 d2.evaluation.evaluator]: Inference done 187/5000. Dataloading: 0.0016 s/iter. Inference: 0.0783 s/iter. Eval: 0.0003 s/iter. Total: 0.0803 s/iter. ETA=0:06:26
[11/05 08:49:09 d2.evaluation.evaluator]: Inference done 253/5000. Dataloading: 0.0016 s/iter. Inference: 0.0772 s/iter. Eval: 0.0003 s/iter. Total: 0.0792 s/iter. ETA=0:06:15
[11/05 08:49:14 d2.evaluation.evaluator]: Inference done 316/5000. Dataloading: 0.0016 s/iter. Inference: 0.0767 s/iter. Eval: 0.0010 s/iter. Total: 0.0793 s/iter. ETA=0:06:11
[11/05 08:49:19 d2.evaluation.evaluator]: Inference done 381/5000. Dataloading: 0.0016 s/iter. Inference: 0.0764 s/iter. Eval: 0.0008 s/iter. Total: 0.0789 s/iter. ETA=0:06:04
[11/05 08:49:24 d2.evaluation.evaluator]: Inference done 446/5000. Dataloading: 0.0016 s/iter. Inference: 0.0763 s/iter. Eval: 0.0008 s/iter. Total: 0.0787 s/iter. ETA=0:05:58
[11/05 08:49:29 d2.evaluation.evaluator]: Inference done 512/5000. Dataloading: 0.0016 s/iter. Inference: 0.0761 s/iter. Eval: 0.0007 s/iter. Total: 0.0785 s/iter. ETA=0:05:52
[11/05 08:49:34 d2.evaluation.evaluator]: Inference done 578/5000. Dataloading: 0.0016 s/iter. Inference: 0.0759 s/iter. Eval: 0.0007 s/iter. Total: 0.0782 s/iter. ETA=0:05:45
[11/05 08:49:40 d2.evaluation.evaluator]: Inference done 642/5000. Dataloading: 0.0016 s/iter. Inference: 0.0760 s/iter. Eval: 0.0006 s/iter. Total: 0.0782 s/iter. ETA=0:05:40
[11/05 08:49:45 d2.evaluation.evaluator]: Inference done 708/5000. Dataloading: 0.0016 s/iter. Inference: 0.0758 s/iter. Eval: 0.0006 s/iter. Total: 0.0780 s/iter. ETA=0:05:34
[11/05 08:49:50 d2.evaluation.evaluator]: Inference done 774/5000. Dataloading: 0.0016 s/iter. Inference: 0.0756 s/iter. Eval: 0.0006 s/iter. Total: 0.0779 s/iter. ETA=0:05:29
[11/05 08:49:55 d2.evaluation.evaluator]: Inference done 840/5000. Dataloading: 0.0016 s/iter. Inference: 0.0755 s/iter. Eval: 0.0006 s/iter. Total: 0.0777 s/iter. ETA=0:05:23
[11/05 08:50:00 d2.evaluation.evaluator]: Inference done 907/5000. Dataloading: 0.0016 s/iter. Inference: 0.0753 s/iter. Eval: 0.0006 s/iter. Total: 0.0775 s/iter. ETA=0:05:17
[11/05 08:50:05 d2.evaluation.evaluator]: Inference done 974/5000. Dataloading: 0.0016 s/iter. Inference: 0.0752 s/iter. Eval: 0.0005 s/iter. Total: 0.0774 s/iter. ETA=0:05:11
[11/05 08:50:10 d2.evaluation.evaluator]: Inference done 1038/5000. Dataloading: 0.0016 s/iter. Inference: 0.0750 s/iter. Eval: 0.0008 s/iter. Total: 0.0774 s/iter. ETA=0:05:06
[11/05 08:50:15 d2.evaluation.evaluator]: Inference done 1104/5000. Dataloading: 0.0016 s/iter. Inference: 0.0750 s/iter. Eval: 0.0007 s/iter. Total: 0.0774 s/iter. ETA=0:05:01
[11/05 08:50:20 d2.evaluation.evaluator]: Inference done 1170/5000. Dataloading: 0.0016 s/iter. Inference: 0.0749 s/iter. Eval: 0.0007 s/iter. Total: 0.0773 s/iter. ETA=0:04:55
[11/05 08:50:25 d2.evaluation.evaluator]: Inference done 1237/5000. Dataloading: 0.0016 s/iter. Inference: 0.0748 s/iter. Eval: 0.0007 s/iter. Total: 0.0772 s/iter. ETA=0:04:50
[11/05 08:50:30 d2.evaluation.evaluator]: Inference done 1303/5000. Dataloading: 0.0016 s/iter. Inference: 0.0748 s/iter. Eval: 0.0007 s/iter. Total: 0.0771 s/iter. ETA=0:04:45
[11/05 08:50:35 d2.evaluation.evaluator]: Inference done 1370/5000. Dataloading: 0.0016 s/iter. Inference: 0.0747 s/iter. Eval: 0.0007 s/iter. Total: 0.0770 s/iter. ETA=0:04:39
[11/05 08:50:40 d2.evaluation.evaluator]: Inference done 1437/5000. Dataloading: 0.0016 s/iter. Inference: 0.0746 s/iter. Eval: 0.0006 s/iter. Total: 0.0769 s/iter. ETA=0:04:34
[11/05 08:50:45 d2.evaluation.evaluator]: Inference done 1505/5000. Dataloading: 0.0016 s/iter. Inference: 0.0745 s/iter. Eval: 0.0006 s/iter. Total: 0.0768 s/iter. ETA=0:04:28
[11/05 08:50:50 d2.evaluation.evaluator]: Inference done 1569/5000. Dataloading: 0.0016 s/iter. Inference: 0.0747 s/iter. Eval: 0.0006 s/iter. Total: 0.0769 s/iter. ETA=0:04:23
[11/05 08:50:55 d2.evaluation.evaluator]: Inference done 1635/5000. Dataloading: 0.0016 s/iter. Inference: 0.0747 s/iter. Eval: 0.0006 s/iter. Total: 0.0769 s/iter. ETA=0:04:18
[11/05 08:51:00 d2.evaluation.evaluator]: Inference done 1701/5000. Dataloading: 0.0016 s/iter. Inference: 0.0746 s/iter. Eval: 0.0006 s/iter. Total: 0.0769 s/iter. ETA=0:04:13
[11/05 08:51:05 d2.evaluation.evaluator]: Inference done 1768/5000. Dataloading: 0.0016 s/iter. Inference: 0.0746 s/iter. Eval: 0.0006 s/iter. Total: 0.0768 s/iter. ETA=0:04:08
[11/05 08:51:10 d2.evaluation.evaluator]: Inference done 1835/5000. Dataloading: 0.0016 s/iter. Inference: 0.0745 s/iter. Eval: 0.0006 s/iter. Total: 0.0768 s/iter. ETA=0:04:02
[11/05 08:51:15 d2.evaluation.evaluator]: Inference done 1902/5000. Dataloading: 0.0016 s/iter. Inference: 0.0745 s/iter. Eval: 0.0006 s/iter. Total: 0.0767 s/iter. ETA=0:03:57
[11/05 08:51:20 d2.evaluation.evaluator]: Inference done 1970/5000. Dataloading: 0.0016 s/iter. Inference: 0.0744 s/iter. Eval: 0.0006 s/iter. Total: 0.0766 s/iter. ETA=0:03:52
[11/05 08:51:25 d2.evaluation.evaluator]: Inference done 2037/5000. Dataloading: 0.0016 s/iter. Inference: 0.0744 s/iter. Eval: 0.0006 s/iter. Total: 0.0766 s/iter. ETA=0:03:46
[11/05 08:51:30 d2.evaluation.evaluator]: Inference done 2104/5000. Dataloading: 0.0016 s/iter. Inference: 0.0743 s/iter. Eval: 0.0005 s/iter. Total: 0.0765 s/iter. ETA=0:03:41
[11/05 08:51:35 d2.evaluation.evaluator]: Inference done 2167/5000. Dataloading: 0.0016 s/iter. Inference: 0.0744 s/iter. Eval: 0.0005 s/iter. Total: 0.0766 s/iter. ETA=0:03:37
[11/05 08:51:40 d2.evaluation.evaluator]: Inference done 2234/5000. Dataloading: 0.0016 s/iter. Inference: 0.0744 s/iter. Eval: 0.0005 s/iter. Total: 0.0766 s/iter. ETA=0:03:31
[11/05 08:51:45 d2.evaluation.evaluator]: Inference done 2301/5000. Dataloading: 0.0016 s/iter. Inference: 0.0743 s/iter. Eval: 0.0005 s/iter. Total: 0.0765 s/iter. ETA=0:03:26
[11/05 08:51:50 d2.evaluation.evaluator]: Inference done 2368/5000. Dataloading: 0.0016 s/iter. Inference: 0.0743 s/iter. Eval: 0.0005 s/iter. Total: 0.0765 s/iter. ETA=0:03:21
[11/05 08:51:55 d2.evaluation.evaluator]: Inference done 2435/5000. Dataloading: 0.0016 s/iter. Inference: 0.0743 s/iter. Eval: 0.0005 s/iter. Total: 0.0765 s/iter. ETA=0:03:16
[11/05 08:52:01 d2.evaluation.evaluator]: Inference done 2502/5000. Dataloading: 0.0016 s/iter. Inference: 0.0743 s/iter. Eval: 0.0005 s/iter. Total: 0.0764 s/iter. ETA=0:03:10
[11/05 08:52:06 d2.evaluation.evaluator]: Inference done 2570/5000. Dataloading: 0.0016 s/iter. Inference: 0.0742 s/iter. Eval: 0.0005 s/iter. Total: 0.0764 s/iter. ETA=0:03:05
[11/05 08:52:11 d2.evaluation.evaluator]: Inference done 2638/5000. Dataloading: 0.0016 s/iter. Inference: 0.0742 s/iter. Eval: 0.0005 s/iter. Total: 0.0763 s/iter. ETA=0:03:00
[11/05 08:52:16 d2.evaluation.evaluator]: Inference done 2705/5000. Dataloading: 0.0016 s/iter. Inference: 0.0741 s/iter. Eval: 0.0005 s/iter. Total: 0.0763 s/iter. ETA=0:02:55
[11/05 08:52:21 d2.evaluation.evaluator]: Inference done 2773/5000. Dataloading: 0.0016 s/iter. Inference: 0.0741 s/iter. Eval: 0.0005 s/iter. Total: 0.0762 s/iter. ETA=0:02:49
[11/05 08:52:26 d2.evaluation.evaluator]: Inference done 2840/5000. Dataloading: 0.0016 s/iter. Inference: 0.0741 s/iter. Eval: 0.0005 s/iter. Total: 0.0762 s/iter. ETA=0:02:44
[11/05 08:52:31 d2.evaluation.evaluator]: Inference done 2906/5000. Dataloading: 0.0016 s/iter. Inference: 0.0741 s/iter. Eval: 0.0005 s/iter. Total: 0.0762 s/iter. ETA=0:02:39
[11/05 08:52:36 d2.evaluation.evaluator]: Inference done 2968/5000. Dataloading: 0.0016 s/iter. Inference: 0.0740 s/iter. Eval: 0.0006 s/iter. Total: 0.0763 s/iter. ETA=0:02:35
[11/05 08:52:41 d2.evaluation.evaluator]: Inference done 3035/5000. Dataloading: 0.0016 s/iter. Inference: 0.0740 s/iter. Eval: 0.0006 s/iter. Total: 0.0763 s/iter. ETA=0:02:29
[11/05 08:52:46 d2.evaluation.evaluator]: Inference done 3102/5000. Dataloading: 0.0016 s/iter. Inference: 0.0740 s/iter. Eval: 0.0006 s/iter. Total: 0.0762 s/iter. ETA=0:02:24
[11/05 08:52:51 d2.evaluation.evaluator]: Inference done 3169/5000. Dataloading: 0.0016 s/iter. Inference: 0.0740 s/iter. Eval: 0.0006 s/iter. Total: 0.0762 s/iter. ETA=0:02:19
[11/05 08:52:56 d2.evaluation.evaluator]: Inference done 3236/5000. Dataloading: 0.0016 s/iter. Inference: 0.0740 s/iter. Eval: 0.0006 s/iter. Total: 0.0762 s/iter. ETA=0:02:14
[11/05 08:53:01 d2.evaluation.evaluator]: Inference done 3303/5000. Dataloading: 0.0016 s/iter. Inference: 0.0740 s/iter. Eval: 0.0006 s/iter. Total: 0.0762 s/iter. ETA=0:02:09
[11/05 08:53:06 d2.evaluation.evaluator]: Inference done 3371/5000. Dataloading: 0.0016 s/iter. Inference: 0.0739 s/iter. Eval: 0.0006 s/iter. Total: 0.0761 s/iter. ETA=0:02:04
[11/05 08:53:11 d2.evaluation.evaluator]: Inference done 3438/5000. Dataloading: 0.0016 s/iter. Inference: 0.0739 s/iter. Eval: 0.0006 s/iter. Total: 0.0761 s/iter. ETA=0:01:58
[11/05 08:53:16 d2.evaluation.evaluator]: Inference done 3506/5000. Dataloading: 0.0016 s/iter. Inference: 0.0739 s/iter. Eval: 0.0006 s/iter. Total: 0.0761 s/iter. ETA=0:01:53
[11/05 08:53:21 d2.evaluation.evaluator]: Inference done 3574/5000. Dataloading: 0.0016 s/iter. Inference: 0.0738 s/iter. Eval: 0.0006 s/iter. Total: 0.0761 s/iter. ETA=0:01:48
[11/05 08:53:26 d2.evaluation.evaluator]: Inference done 3641/5000. Dataloading: 0.0016 s/iter. Inference: 0.0738 s/iter. Eval: 0.0006 s/iter. Total: 0.0760 s/iter. ETA=0:01:43
[11/05 08:53:31 d2.evaluation.evaluator]: Inference done 3708/5000. Dataloading: 0.0016 s/iter. Inference: 0.0738 s/iter. Eval: 0.0006 s/iter. Total: 0.0760 s/iter. ETA=0:01:38
[11/05 08:53:36 d2.evaluation.evaluator]: Inference done 3775/5000. Dataloading: 0.0016 s/iter. Inference: 0.0738 s/iter. Eval: 0.0006 s/iter. Total: 0.0760 s/iter. ETA=0:01:33
slurmstepd: error: *** JOB 911902 ON atl1-1-01-005-13-0 CANCELLED AT 2024-11-05T08:53:38 ***
---------------------------------------
Begin Slurm Epilog: Nov-05-2024 08:53:40
Job ID:        911902
Array Job ID:  _4294967294
User ID:       zyahn3
Account:       scs
Job name:      TOG_Plus_R50
Resources:     cpu=1,gres/gpu:a100=1,mem=128G,node=1
Rsrc Used:     cput=00:05:41,vmem=0,walltime=00:05:41,mem=3664156K,energy_used=0
Partition:     coc-gpu
Nodes:         atl1-1-01-005-13-0
---------------------------------------
