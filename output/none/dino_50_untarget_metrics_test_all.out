---------------------------------------
Begin Slurm Prolog: Oct-22-2024 15:52:12
Job ID:    879568
User ID:   zyahn3
Account:   scs
Job name:  TOG_Plus_R50
Partition: coc-gpu
---------------------------------------
/storage/ice1/5/9/zyahn3/TOG_plus/detrex/detrex/layers/dcn_v3.py:23: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @custom_fwd
/storage/ice1/5/9/zyahn3/TOG_plus/detrex/detrex/layers/dcn_v3.py:52: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  @custom_bwd
[10/22 15:52:48 detectron2]: Rank of current process: 0. World size: 1
[10/22 15:52:49 detectron2]: Environment info:
-------------------------------  ----------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:12:24) [GCC 11.2.0]
numpy                            1.26.4
detectron2                       0.6 @/storage/ice1/5/9/zyahn3/TOG_plus/detrex/detectron2/detectron2
Compiler                         GCC 12.3
CUDA compiler                    not available
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.4.1 @/home/hice1/zyahn3/.conda/envs/TOG_test/lib/python3.12/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA A100-PCIE-40GB (arch=8.0)
Driver version                   555.42.02
CUDA_HOME                        /usr/local/cuda
Pillow                           10.4.0
torchvision                      0.19.1 @/home/hice1/zyahn3/.conda/envs/TOG_test/lib/python3.12/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.10.0
-------------------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[10/22 15:52:49 detectron2]: Command line arguments: Namespace(config_file='detrex/projects/dino/configs/dino-resnet/dino_r50_4scale_12ep.py', resume=False, eval_only=True, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:53103', opts=['train.init_checkpoint=model_files/dino_r50_4scale.pth', 'attack=untargeted', 'attack_mode=untargeted', 'sample=0.005'])
[10/22 15:52:49 detectron2]: Contents of args.config_file=detrex/projects/dino/configs/dino-resnet/dino_r50_4scale_12ep.py:
[38;5;204mfrom[39m[38;5;15m [39m[38;5;15mdetrex[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;204mimport[39m[38;5;15m [39m[38;5;15mget_config[39m
[38;5;204mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mdino_r50[39m[38;5;15m [39m[38;5;204mimport[39m[38;5;15m [39m[38;5;15mmodel[39m

[38;5;245m# get default config[39m
[38;5;15mdataloader[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/data/coco_detr.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;204m.[39m[38;5;15mdataloader[39m
[38;5;15moptimizer[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/optim.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;204m.[39m[38;5;15mAdamW[39m
[38;5;15mlr_multiplier[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/coco_schedule.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;204m.[39m[38;5;15mlr_multiplier_12ep[39m
[38;5;15mtrain[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/train.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;204m.[39m[38;5;15mtrain[39m

[38;5;245m# modify training config[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15minit_checkpoint[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m[38;5;186m"[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./output/dino_r50_4scale_12ep[39m[38;5;186m"[39m

[38;5;245m# max training iterations[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mmax_iter[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15meval_period[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mlog_period[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mcheckpointer[39m[38;5;204m.[39m[38;5;15mperiod[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m5000[39m

[38;5;245m# gradient clipping for training[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mclip_grad[39m[38;5;204m.[39m[38;5;15menabled[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mclip_grad[39m[38;5;204m.[39m[38;5;15mparams[39m[38;5;204m.[39m[38;5;15mmax_norm[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mclip_grad[39m[38;5;204m.[39m[38;5;15mparams[39m[38;5;204m.[39m[38;5;15mnorm_type[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;245m# set training devices[39m
[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcuda[39m[38;5;186m"[39m
[38;5;15mmodel[39m[38;5;204m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mdevice[39m

[38;5;245m# modify optimizer config[39m
[38;5;15moptimizer[39m[38;5;204m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;204m.[39m[38;5;15mbetas[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15m([39m[38;5;141m0.9[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m0.999[39m[38;5;15m)[39m
[38;5;15moptimizer[39m[38;5;204m.[39m[38;5;15mweight_decay[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;204m.[39m[38;5;15mparams[39m[38;5;204m.[39m[38;5;15mlr_factor_func[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;81mlambda[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m[38;5;15m [39m[38;5;81mif[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbackbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;204min[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m [39m[38;5;81melse[39m[38;5;15m [39m[38;5;141m1[39m

[38;5;245m# modify dataloader config[39m
[38;5;15mdataloader[39m[38;5;204m.[39m[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mnum_workers[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m16[39m

[38;5;245m# please notice that this is total batch size.[39m
[38;5;245m# surpose you're using 4 gpus for training and the batch size for[39m
[38;5;245m# each gpu is 16/4 = 4[39m
[38;5;15mdataloader[39m[38;5;204m.[39m[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15mtotal_batch_size[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;141m16[39m

[38;5;245m# dump the testing results into output_dir for visualization[39m
[38;5;15mdataloader[39m[38;5;204m.[39m[38;5;15mevaluator[39m[38;5;204m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;204m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;204m.[39m[38;5;15moutput_dir[39m

[38;5;15mattack[39m[38;5;204m=[39m[38;5;81mNone[39m
[38;5;15mattack_mode[39m[38;5;204m=[39m[38;5;81mNone[39m
[38;5;15msample[39m[38;5;204m=[39m[38;5;141m1.0[39m

WARNING [10/22 15:52:49 d2.config.lazy]: The config contains objects that cannot serialize to a valid yaml. ./output/dino_r50_4scale_12ep/config.yaml is human-readable but cannot be loaded.
WARNING [10/22 15:52:49 d2.config.lazy]: Config is saved using cloudpickle at ./output/dino_r50_4scale_12ep/config.yaml.pkl.
[10/22 15:52:49 detectron2]: Full config saved to ./output/dino_r50_4scale_12ep/config.yaml
[10/22 15:52:49 d2.utils.env]: Using a generated random seed 52943635
[10/22 15:52:51 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from model_files/dino_r50_4scale.pth ...
[10/22 15:52:51 fvcore.common.checkpoint]: [Checkpointer] Loading from model_files/dino_r50_4scale.pth ...
/home/hice1/zyahn3/.conda/envs/TOG_test/lib/python3.12/site-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(f, map_location=torch.device("cpu"))
[10/22 15:52:51 detectron2]: Run evaluation under eval-only mode
[10/22 15:52:51 detectron2]: Run evaluation without EMA.
[10/22 15:52:52 d2.data.datasets.coco]: Loaded 5000 images in COCO format from /home/hice1/zyahn3/scratch/TOG_plus/dataset/coco/annotations/instances_val2017.json
[10/22 15:52:52 d2.data.build]: Distribution of instances among all 80 categories:
|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |
[10/22 15:52:52 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[10/22 15:52:52 d2.data.common]: Serializing 5000 elements to byte tensors and concatenating them all ...
[10/22 15:52:52 d2.data.common]: Serialized dataset takes 19.26 MiB
/home/hice1/zyahn3/.conda/envs/TOG_test/lib/python3.12/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
[10/22 15:52:52 d2.evaluation.evaluator]: Start inference on 5000 batches
Doing attack: <function tog_untargeted at 0x15549a918040>
/home/hice1/zyahn3/.conda/envs/TOG_test/lib/python3.12/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1724789220573/work/aten/src/ATen/native/TensorShape.cpp:3609.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
ATTN untarget: bbox loss: 1364.65625 Class loss: 1.2363537549972534 Norm loss: 0.0
ATTN untarget: bbox loss: 1364.65625 Class loss: 1.2363537549972534 Norm loss: 0.0
ATTN untarget: bbox loss: 1364.65625 Class loss: 1.2363537549972534 Norm loss: 0.0
ATTN untarget: bbox loss: 1364.65625 Class loss: 1.2363537549972534 Norm loss: 0.0
ATTN untarget: bbox loss: 1364.65625 Class loss: 1.2363537549972534 Norm loss: 0.0
ATTN untarget: bbox loss: 1364.65625 Class loss: 1.2363537549972534 Norm loss: 0.0
ATTN untarget: bbox loss: 1364.65625 Class loss: 1.2363537549972534 Norm loss: 0.0
ATTN untarget: bbox loss: 1364.65625 Class loss: 1.2363537549972534 Norm loss: 0.0
ATTN untarget: bbox loss: 1364.65625 Class loss: 1.2363537549972534 Norm loss: 0.0
ATTN untarget: bbox loss: 1364.65625 Class loss: 1.2363537549972534 Norm loss: 0.0
[10/22 15:53:07 d2.evaluation.evaluator]: Inference done 125/5000. Dataloading: 0.0275 s/iter. Inference: 0.0934 s/iter. Eval: 0.0001 s/iter. Total: 0.1209 s/iter. ETA=0:09:49
ATTN untarget: bbox loss: 1208.2845458984375 Class loss: 1.3903571367263794 Norm loss: 0.0
ATTN untarget: bbox loss: 1208.2845458984375 Class loss: 1.395427942276001 Norm loss: 0.0
ATTN untarget: bbox loss: 1208.284423828125 Class loss: 1.3934217691421509 Norm loss: 0.0
ATTN untarget: bbox loss: 1208.2840576171875 Class loss: 1.3962727785110474 Norm loss: 0.0
ATTN untarget: bbox loss: 1208.284423828125 Class loss: 1.3932429552078247 Norm loss: 0.0
ATTN untarget: bbox loss: 1208.284423828125 Class loss: 1.3938709497451782 Norm loss: 0.0
ATTN untarget: bbox loss: 1208.284423828125 Class loss: 1.3941848278045654 Norm loss: 0.0
ATTN untarget: bbox loss: 1208.284423828125 Class loss: 1.394577980041504 Norm loss: 0.0
ATTN untarget: bbox loss: 1208.284423828125 Class loss: 1.3946475982666016 Norm loss: 0.0
ATTN untarget: bbox loss: 1208.284423828125 Class loss: 1.394665002822876 Norm loss: 0.0
ATTN untarget: bbox loss: 921.2493896484375 Class loss: 1.5178451538085938 Norm loss: 0.0
ATTN untarget: bbox loss: 921.2493896484375 Class loss: 1.518067717552185 Norm loss: 0.0
ATTN untarget: bbox loss: 921.2476806640625 Class loss: 1.5193567276000977 Norm loss: 0.0
ATTN untarget: bbox loss: 921.2476806640625 Class loss: 1.5188724994659424 Norm loss: 0.0
ATTN untarget: bbox loss: 921.2476806640625 Class loss: 1.5196441411972046 Norm loss: 0.0
ATTN untarget: bbox loss: 921.2476806640625 Class loss: 1.5201700925827026 Norm loss: 0.0
ATTN untarget: bbox loss: 921.2476806640625 Class loss: 1.5202215909957886 Norm loss: 0.0
ATTN untarget: bbox loss: 921.2476806640625 Class loss: 1.5202324390411377 Norm loss: 0.0
ATTN untarget: bbox loss: 921.2476806640625 Class loss: 1.5204676389694214 Norm loss: 0.0
ATTN untarget: bbox loss: 921.2476196289062 Class loss: 1.5204273462295532 Norm loss: 0.0
[10/22 15:53:15 d2.evaluation.evaluator]: Inference done 349/5000. Dataloading: 0.0205 s/iter. Inference: 0.0451 s/iter. Eval: 0.0000 s/iter. Total: 0.0656 s/iter. ETA=0:05:05
ATTN untarget: bbox loss: 1210.4593505859375 Class loss: 1.399635672569275 Norm loss: 0.0
ATTN untarget: bbox loss: 1210.4593505859375 Class loss: 1.3996046781539917 Norm loss: 0.0
ATTN untarget: bbox loss: 1210.4593505859375 Class loss: 1.3996083736419678 Norm loss: 0.0
ATTN untarget: bbox loss: 1210.4593505859375 Class loss: 1.3996039628982544 Norm loss: 0.0
ATTN untarget: bbox loss: 1210.4593505859375 Class loss: 1.399606466293335 Norm loss: 0.0
ATTN untarget: bbox loss: 1210.4593505859375 Class loss: 1.3996050357818604 Norm loss: 0.0
ATTN untarget: bbox loss: 1210.4593505859375 Class loss: 1.399606466293335 Norm loss: 0.0
ATTN untarget: bbox loss: 1210.4593505859375 Class loss: 1.3996050357818604 Norm loss: 0.0
ATTN untarget: bbox loss: 1210.4593505859375 Class loss: 1.399606466293335 Norm loss: 0.0
ATTN untarget: bbox loss: 1210.4593505859375 Class loss: 1.3996050357818604 Norm loss: 0.0
ATTN untarget: bbox loss: 743.7017211914062 Class loss: 1.319744348526001 Norm loss: 0.0
ATTN untarget: bbox loss: 743.7017211914062 Class loss: 1.3197450637817383 Norm loss: 0.0
ATTN untarget: bbox loss: 743.7017211914062 Class loss: 1.3198423385620117 Norm loss: 0.0
ATTN untarget: bbox loss: 743.70166015625 Class loss: 1.3198472261428833 Norm loss: 0.0
ATTN untarget: bbox loss: 743.7017822265625 Class loss: 1.31952702999115 Norm loss: 0.0
ATTN untarget: bbox loss: 743.7017211914062 Class loss: 1.3199011087417603 Norm loss: 0.0
ATTN untarget: bbox loss: 743.7017211914062 Class loss: 1.3198647499084473 Norm loss: 0.0
ATTN untarget: bbox loss: 743.7017211914062 Class loss: 1.3198975324630737 Norm loss: 0.0
ATTN untarget: bbox loss: 743.7017211914062 Class loss: 1.3198286294937134 Norm loss: 0.0
ATTN untarget: bbox loss: 743.70166015625 Class loss: 1.319966197013855 Norm loss: 0.0
[10/22 15:53:22 d2.evaluation.evaluator]: Inference done 550/5000. Dataloading: 0.0188 s/iter. Inference: 0.0359 s/iter. Eval: 0.0000 s/iter. Total: 0.0548 s/iter. ETA=0:04:03
ATTN untarget: bbox loss: 676.5158081054688 Class loss: 1.4596604108810425 Norm loss: 0.0
ATTN untarget: bbox loss: 676.5158081054688 Class loss: 1.4595787525177002 Norm loss: 0.0
ATTN untarget: bbox loss: 676.5157470703125 Class loss: 1.459629774093628 Norm loss: 0.0
ATTN untarget: bbox loss: 676.5157470703125 Class loss: 1.4596397876739502 Norm loss: 0.0
ATTN untarget: bbox loss: 676.5157470703125 Class loss: 1.4596482515335083 Norm loss: 0.0
ATTN untarget: bbox loss: 676.5157470703125 Class loss: 1.4596326351165771 Norm loss: 0.0
ATTN untarget: bbox loss: 676.5157470703125 Class loss: 1.4596508741378784 Norm loss: 0.0
ATTN untarget: bbox loss: 676.515625 Class loss: 1.4596468210220337 Norm loss: 0.0
ATTN untarget: bbox loss: 676.5157470703125 Class loss: 1.4596493244171143 Norm loss: 0.0
ATTN untarget: bbox loss: 676.5157470703125 Class loss: 1.459646463394165 Norm loss: 0.0
[10/22 15:53:32 d2.evaluation.evaluator]: Inference done 1033/5000. Dataloading: 0.0177 s/iter. Inference: 0.0212 s/iter. Eval: 0.0000 s/iter. Total: 0.0389 s/iter. ETA=0:02:34
ATTN untarget: bbox loss: 799.267333984375 Class loss: 1.335852861404419 Norm loss: 0.0
ATTN untarget: bbox loss: 799.2671508789062 Class loss: 1.334517240524292 Norm loss: 0.0
ATTN untarget: bbox loss: 799.267333984375 Class loss: 1.3358930349349976 Norm loss: 0.0
ATTN untarget: bbox loss: 799.2673950195312 Class loss: 1.3358237743377686 Norm loss: 0.0
ATTN untarget: bbox loss: 799.2672119140625 Class loss: 1.3344773054122925 Norm loss: 0.0
ATTN untarget: bbox loss: 799.2672119140625 Class loss: 1.3344683647155762 Norm loss: 0.0
ATTN untarget: bbox loss: 799.2672119140625 Class loss: 1.3344814777374268 Norm loss: 0.0
ATTN untarget: bbox loss: 799.2672119140625 Class loss: 1.3345177173614502 Norm loss: 0.0
ATTN untarget: bbox loss: 799.2673950195312 Class loss: 1.3358148336410522 Norm loss: 0.0
ATTN untarget: bbox loss: 799.2673950195312 Class loss: 1.336007833480835 Norm loss: 0.0
[10/22 15:53:40 d2.evaluation.evaluator]: Inference done 1385/5000. Dataloading: 0.0174 s/iter. Inference: 0.0172 s/iter. Eval: 0.0000 s/iter. Total: 0.0346 s/iter. ETA=0:02:05
ATTN untarget: bbox loss: 870.852294921875 Class loss: 1.3656842708587646 Norm loss: 0.0
ATTN untarget: bbox loss: 870.8521118164062 Class loss: 1.3666963577270508 Norm loss: 0.0
ATTN untarget: bbox loss: 870.8523559570312 Class loss: 1.3636270761489868 Norm loss: 0.0
ATTN untarget: bbox loss: 870.852294921875 Class loss: 1.3675363063812256 Norm loss: 0.0
ATTN untarget: bbox loss: 870.8524169921875 Class loss: 1.3693208694458008 Norm loss: 0.0
ATTN untarget: bbox loss: 870.8524169921875 Class loss: 1.3696248531341553 Norm loss: 0.0
ATTN untarget: bbox loss: 870.8524169921875 Class loss: 1.3710739612579346 Norm loss: 0.0
ATTN untarget: bbox loss: 870.8523559570312 Class loss: 1.3686468601226807 Norm loss: 0.0
ATTN untarget: bbox loss: 870.8524169921875 Class loss: 1.3726418018341064 Norm loss: 0.0
ATTN untarget: bbox loss: 870.8523559570312 Class loss: 1.368950366973877 Norm loss: 0.0
ATTN untarget: bbox loss: 803.8756103515625 Class loss: 1.5171751976013184 Norm loss: 0.0
ATTN untarget: bbox loss: 803.8756713867188 Class loss: 1.5081455707550049 Norm loss: 0.0
ATTN untarget: bbox loss: 803.8756713867188 Class loss: 1.5082131624221802 Norm loss: 0.0
ATTN untarget: bbox loss: 803.8756713867188 Class loss: 1.5082308053970337 Norm loss: 0.0
ATTN untarget: bbox loss: 803.8756103515625 Class loss: 1.5171879529953003 Norm loss: 0.0
ATTN untarget: bbox loss: 803.8756103515625 Class loss: 1.51714026927948 Norm loss: 0.0
ATTN untarget: bbox loss: 803.8756103515625 Class loss: 1.5171425342559814 Norm loss: 0.0
ATTN untarget: bbox loss: 803.8756713867188 Class loss: 1.5082180500030518 Norm loss: 0.0
ATTN untarget: bbox loss: 803.8756103515625 Class loss: 1.516889214515686 Norm loss: 0.0
ATTN untarget: bbox loss: 803.8756713867188 Class loss: 1.5082180500030518 Norm loss: 0.0
[10/22 15:53:47 d2.evaluation.evaluator]: Inference done 1545/5000. Dataloading: 0.0172 s/iter. Inference: 0.0182 s/iter. Eval: 0.0000 s/iter. Total: 0.0354 s/iter. ETA=0:02:02
ATTN untarget: bbox loss: 1491.47900390625 Class loss: 1.146287441253662 Norm loss: 0.0
ATTN untarget: bbox loss: 1491.4791259765625 Class loss: 1.149631381034851 Norm loss: 0.0
ATTN untarget: bbox loss: 1491.4791259765625 Class loss: 1.1515228748321533 Norm loss: 0.0
ATTN untarget: bbox loss: 1491.4791259765625 Class loss: 1.151930809020996 Norm loss: 0.0
ATTN untarget: bbox loss: 1491.4791259765625 Class loss: 1.1561585664749146 Norm loss: 0.0
ATTN untarget: bbox loss: 1491.4791259765625 Class loss: 1.1513835191726685 Norm loss: 0.0
ATTN untarget: bbox loss: 1491.4791259765625 Class loss: 1.1551032066345215 Norm loss: 0.0
ATTN untarget: bbox loss: 1491.4791259765625 Class loss: 1.1530048847198486 Norm loss: 0.0
ATTN untarget: bbox loss: 1491.4791259765625 Class loss: 1.1553709506988525 Norm loss: 0.0
ATTN untarget: bbox loss: 1491.4791259765625 Class loss: 1.152693510055542 Norm loss: 0.0
ATTN untarget: bbox loss: 665.5015258789062 Class loss: 1.4832872152328491 Norm loss: 0.0
ATTN untarget: bbox loss: 665.5015258789062 Class loss: 1.4828821420669556 Norm loss: 0.0
ATTN untarget: bbox loss: 665.501708984375 Class loss: 1.4829703569412231 Norm loss: 0.0
ATTN untarget: bbox loss: 665.5016479492188 Class loss: 1.4829845428466797 Norm loss: 0.0
ATTN untarget: bbox loss: 665.501708984375 Class loss: 1.4829024076461792 Norm loss: 0.0
ATTN untarget: bbox loss: 665.5015258789062 Class loss: 1.4829200506210327 Norm loss: 0.0
ATTN untarget: bbox loss: 665.501708984375 Class loss: 1.4831500053405762 Norm loss: 0.0
ATTN untarget: bbox loss: 665.501708984375 Class loss: 1.4831504821777344 Norm loss: 0.0
ATTN untarget: bbox loss: 665.5016479492188 Class loss: 1.483078122138977 Norm loss: 0.0
ATTN untarget: bbox loss: 665.5016479492188 Class loss: 1.4829171895980835 Norm loss: 0.0
[10/22 15:53:54 d2.evaluation.evaluator]: Inference done 1732/5000. Dataloading: 0.0171 s/iter. Inference: 0.0184 s/iter. Eval: 0.0000 s/iter. Total: 0.0355 s/iter. ETA=0:01:55
ATTN untarget: bbox loss: 979.3369140625 Class loss: 1.5937771797180176 Norm loss: 0.0
ATTN untarget: bbox loss: 979.3369140625 Class loss: 1.5932517051696777 Norm loss: 0.0
ATTN untarget: bbox loss: 979.3369140625 Class loss: 1.5937144756317139 Norm loss: 0.0
ATTN untarget: bbox loss: 979.3369140625 Class loss: 1.5944750308990479 Norm loss: 0.0
ATTN untarget: bbox loss: 979.3369140625 Class loss: 1.5936189889907837 Norm loss: 0.0
ATTN untarget: bbox loss: 979.3369750976562 Class loss: 1.5936384201049805 Norm loss: 0.0
ATTN untarget: bbox loss: 979.3369140625 Class loss: 1.5933793783187866 Norm loss: 0.0
ATTN untarget: bbox loss: 979.3368530273438 Class loss: 1.5935734510421753 Norm loss: 0.0
ATTN untarget: bbox loss: 979.3369140625 Class loss: 1.5920522212982178 Norm loss: 0.0
ATTN untarget: bbox loss: 979.3369140625 Class loss: 1.5935508012771606 Norm loss: 0.0
[10/22 15:54:00 d2.evaluation.evaluator]: Inference done 2015/5000. Dataloading: 0.0169 s/iter. Inference: 0.0169 s/iter. Eval: 0.0000 s/iter. Total: 0.0338 s/iter. ETA=0:01:40
ATTN untarget: bbox loss: 815.6588745117188 Class loss: 1.4333962202072144 Norm loss: 0.0
ATTN untarget: bbox loss: 815.6588745117188 Class loss: 1.4323604106903076 Norm loss: 0.0
ATTN untarget: bbox loss: 815.6588745117188 Class loss: 1.432334065437317 Norm loss: 0.0
ATTN untarget: bbox loss: 815.6588745117188 Class loss: 1.4325146675109863 Norm loss: 0.0
ATTN untarget: bbox loss: 815.6588745117188 Class loss: 1.4325227737426758 Norm loss: 0.0
ATTN untarget: bbox loss: 815.6588745117188 Class loss: 1.4335975646972656 Norm loss: 0.0
ATTN untarget: bbox loss: 815.6588745117188 Class loss: 1.4324177503585815 Norm loss: 0.0
ATTN untarget: bbox loss: 815.6588745117188 Class loss: 1.4333449602127075 Norm loss: 0.0
ATTN untarget: bbox loss: 815.6588745117188 Class loss: 1.4323368072509766 Norm loss: 0.0
ATTN untarget: bbox loss: 815.6588745117188 Class loss: 1.4334266185760498 Norm loss: 0.0
[10/22 15:54:06 d2.evaluation.evaluator]: Inference done 2211/5000. Dataloading: 0.0168 s/iter. Inference: 0.0163 s/iter. Eval: 0.0000 s/iter. Total: 0.0332 s/iter. ETA=0:01:32
ATTN untarget: bbox loss: 1096.62841796875 Class loss: 1.2774899005889893 Norm loss: 0.0
ATTN untarget: bbox loss: 1096.62841796875 Class loss: 1.2774924039840698 Norm loss: 0.0
ATTN untarget: bbox loss: 1096.62841796875 Class loss: 1.2774919271469116 Norm loss: 0.0
ATTN untarget: bbox loss: 1096.62841796875 Class loss: 1.2774931192398071 Norm loss: 0.0
ATTN untarget: bbox loss: 1096.62841796875 Class loss: 1.2774912118911743 Norm loss: 0.0
ATTN untarget: bbox loss: 1096.62841796875 Class loss: 1.2774933576583862 Norm loss: 0.0
ATTN untarget: bbox loss: 1096.62841796875 Class loss: 1.2774604558944702 Norm loss: 0.0
ATTN untarget: bbox loss: 1096.62841796875 Class loss: 1.2774934768676758 Norm loss: 0.0
ATTN untarget: bbox loss: 1096.62841796875 Class loss: 1.277459979057312 Norm loss: 0.0
ATTN untarget: bbox loss: 1096.62841796875 Class loss: 1.2774598598480225 Norm loss: 0.0
[10/22 15:54:12 d2.evaluation.evaluator]: Inference done 2462/5000. Dataloading: 0.0168 s/iter. Inference: 0.0155 s/iter. Eval: 0.0000 s/iter. Total: 0.0323 s/iter. ETA=0:01:21
ATTN untarget: bbox loss: 861.4779052734375 Class loss: 1.4753037691116333 Norm loss: 0.0
ATTN untarget: bbox loss: 861.4779052734375 Class loss: 1.481153964996338 Norm loss: 0.0
ATTN untarget: bbox loss: 861.4779052734375 Class loss: 1.484609603881836 Norm loss: 0.0
ATTN untarget: bbox loss: 861.4779052734375 Class loss: 1.487673044204712 Norm loss: 0.0
ATTN untarget: bbox loss: 861.4779052734375 Class loss: 1.491023063659668 Norm loss: 0.0
ATTN untarget: bbox loss: 861.4779052734375 Class loss: 1.491864562034607 Norm loss: 0.0
ATTN untarget: bbox loss: 861.4779052734375 Class loss: 1.4919400215148926 Norm loss: 0.0
ATTN untarget: bbox loss: 861.4779052734375 Class loss: 1.4912108182907104 Norm loss: 0.0
ATTN untarget: bbox loss: 861.4779052734375 Class loss: 1.492616057395935 Norm loss: 0.0
ATTN untarget: bbox loss: 861.4779052734375 Class loss: 1.4915977716445923 Norm loss: 0.0
ATTN untarget: bbox loss: 1000.4923095703125 Class loss: 1.4230512380599976 Norm loss: 0.0
ATTN untarget: bbox loss: 1000.4923095703125 Class loss: 1.423053503036499 Norm loss: 0.0
ATTN untarget: bbox loss: 1000.4923095703125 Class loss: 1.4230464696884155 Norm loss: 0.0
ATTN untarget: bbox loss: 1000.4923095703125 Class loss: 1.42304527759552 Norm loss: 0.0
ATTN untarget: bbox loss: 1000.4923095703125 Class loss: 1.4230517148971558 Norm loss: 0.0
ATTN untarget: bbox loss: 1000.4923095703125 Class loss: 1.42305588722229 Norm loss: 0.0
ATTN untarget: bbox loss: 1000.4923095703125 Class loss: 1.4230611324310303 Norm loss: 0.0
ATTN untarget: bbox loss: 1000.4923095703125 Class loss: 1.423058271408081 Norm loss: 0.0
ATTN untarget: bbox loss: 1000.4923095703125 Class loss: 1.4230518341064453 Norm loss: 0.0
ATTN untarget: bbox loss: 1000.4923095703125 Class loss: 1.4230519533157349 Norm loss: 0.0
[10/22 15:54:19 d2.evaluation.evaluator]: Inference done 2658/5000. Dataloading: 0.0167 s/iter. Inference: 0.0160 s/iter. Eval: 0.0000 s/iter. Total: 0.0327 s/iter. ETA=0:01:16
ATTN untarget: bbox loss: 933.172119140625 Class loss: 1.511854648590088 Norm loss: 0.0
ATTN untarget: bbox loss: 933.1721801757812 Class loss: 1.5117506980895996 Norm loss: 0.0
ATTN untarget: bbox loss: 933.172119140625 Class loss: 1.511860728263855 Norm loss: 0.0
ATTN untarget: bbox loss: 933.1721801757812 Class loss: 1.5117487907409668 Norm loss: 0.0
ATTN untarget: bbox loss: 933.172119140625 Class loss: 1.5118613243103027 Norm loss: 0.0
ATTN untarget: bbox loss: 933.1721801757812 Class loss: 1.5120713710784912 Norm loss: 0.0
ATTN untarget: bbox loss: 933.172119140625 Class loss: 1.5118706226348877 Norm loss: 0.0
ATTN untarget: bbox loss: 933.172119140625 Class loss: 1.5118681192398071 Norm loss: 0.0
ATTN untarget: bbox loss: 933.172119140625 Class loss: 1.5118720531463623 Norm loss: 0.0
ATTN untarget: bbox loss: 933.172119140625 Class loss: 1.5118697881698608 Norm loss: 0.0
ATTN untarget: bbox loss: 1011.4326782226562 Class loss: 1.4280644655227661 Norm loss: 0.0
ATTN untarget: bbox loss: 1011.4326782226562 Class loss: 1.4280399084091187 Norm loss: 0.0
ATTN untarget: bbox loss: 1011.4328002929688 Class loss: 1.4284253120422363 Norm loss: 0.0
ATTN untarget: bbox loss: 1011.4326782226562 Class loss: 1.4290333986282349 Norm loss: 0.0
ATTN untarget: bbox loss: 1011.4326782226562 Class loss: 1.4292656183242798 Norm loss: 0.0
ATTN untarget: bbox loss: 1011.4326782226562 Class loss: 1.4292904138565063 Norm loss: 0.0
ATTN untarget: bbox loss: 1011.4326782226562 Class loss: 1.429263949394226 Norm loss: 0.0
ATTN untarget: bbox loss: 1011.4326782226562 Class loss: 1.4293323755264282 Norm loss: 0.0
ATTN untarget: bbox loss: 1011.4326782226562 Class loss: 1.429336667060852 Norm loss: 0.0
ATTN untarget: bbox loss: 1011.4326782226562 Class loss: 1.429273247718811 Norm loss: 0.0
[10/22 15:54:31 d2.evaluation.evaluator]: Inference done 3170/5000. Dataloading: 0.0166 s/iter. Inference: 0.0146 s/iter. Eval: 0.0000 s/iter. Total: 0.0313 s/iter. ETA=0:00:57
ATTN untarget: bbox loss: 1382.5299072265625 Class loss: 1.471994400024414 Norm loss: 0.0
ATTN untarget: bbox loss: 1382.5299072265625 Class loss: 1.471994400024414 Norm loss: 0.0
ATTN untarget: bbox loss: 1382.5299072265625 Class loss: 1.471994400024414 Norm loss: 0.0
ATTN untarget: bbox loss: 1382.5299072265625 Class loss: 1.471994400024414 Norm loss: 0.0
ATTN untarget: bbox loss: 1382.5299072265625 Class loss: 1.471994400024414 Norm loss: 0.0
ATTN untarget: bbox loss: 1382.5299072265625 Class loss: 1.471994400024414 Norm loss: 0.0
ATTN untarget: bbox loss: 1382.5299072265625 Class loss: 1.471994400024414 Norm loss: 0.0
ATTN untarget: bbox loss: 1382.5299072265625 Class loss: 1.471994400024414 Norm loss: 0.0
ATTN untarget: bbox loss: 1382.5299072265625 Class loss: 1.471994400024414 Norm loss: 0.0
ATTN untarget: bbox loss: 1382.5299072265625 Class loss: 1.471994400024414 Norm loss: 0.0
[10/22 15:54:38 d2.evaluation.evaluator]: Inference done 3420/5000. Dataloading: 0.0166 s/iter. Inference: 0.0142 s/iter. Eval: 0.0000 s/iter. Total: 0.0308 s/iter. ETA=0:00:48
ATTN untarget: bbox loss: 846.0744018554688 Class loss: 1.5225296020507812 Norm loss: 0.0
ATTN untarget: bbox loss: 846.074462890625 Class loss: 1.5225334167480469 Norm loss: 0.0
ATTN untarget: bbox loss: 846.0744018554688 Class loss: 1.5224629640579224 Norm loss: 0.0
ATTN untarget: bbox loss: 846.074462890625 Class loss: 1.5223270654678345 Norm loss: 0.0
ATTN untarget: bbox loss: 846.074462890625 Class loss: 1.5225602388381958 Norm loss: 0.0
ATTN untarget: bbox loss: 846.0745239257812 Class loss: 1.5225430727005005 Norm loss: 0.0
ATTN untarget: bbox loss: 846.074462890625 Class loss: 1.5226553678512573 Norm loss: 0.0
ATTN untarget: bbox loss: 846.0745239257812 Class loss: 1.5226060152053833 Norm loss: 0.0
ATTN untarget: bbox loss: 846.074462890625 Class loss: 1.5225589275360107 Norm loss: 0.0
ATTN untarget: bbox loss: 846.074462890625 Class loss: 1.5226062536239624 Norm loss: 0.0
[10/22 15:54:48 d2.evaluation.evaluator]: Inference done 3912/5000. Dataloading: 0.0166 s/iter. Inference: 0.0130 s/iter. Eval: 0.0000 s/iter. Total: 0.0296 s/iter. ETA=0:00:32
ATTN untarget: bbox loss: 741.4365234375 Class loss: 1.3498878479003906 Norm loss: 0.0
ATTN untarget: bbox loss: 741.4365234375 Class loss: 1.3567439317703247 Norm loss: 0.0
ATTN untarget: bbox loss: 741.435791015625 Class loss: 1.3571422100067139 Norm loss: 0.0
ATTN untarget: bbox loss: 741.435791015625 Class loss: 1.3603726625442505 Norm loss: 0.0
ATTN untarget: bbox loss: 741.435791015625 Class loss: 1.3652873039245605 Norm loss: 0.0
ATTN untarget: bbox loss: 741.435791015625 Class loss: 1.365964651107788 Norm loss: 0.0
ATTN untarget: bbox loss: 741.4358520507812 Class loss: 1.3669264316558838 Norm loss: 0.0
ATTN untarget: bbox loss: 741.435791015625 Class loss: 1.3677979707717896 Norm loss: 0.0
ATTN untarget: bbox loss: 741.435791015625 Class loss: 1.3679683208465576 Norm loss: 0.0
ATTN untarget: bbox loss: 741.4356689453125 Class loss: 1.367279052734375 Norm loss: 0.0
ATTN untarget: bbox loss: 922.342529296875 Class loss: 1.508848786354065 Norm loss: 0.0
ATTN untarget: bbox loss: 922.3425903320312 Class loss: 1.5080317258834839 Norm loss: 0.0
ATTN untarget: bbox loss: 922.342529296875 Class loss: 1.5080907344818115 Norm loss: 0.0
ATTN untarget: bbox loss: 922.3425903320312 Class loss: 1.5079150199890137 Norm loss: 0.0
ATTN untarget: bbox loss: 922.3425903320312 Class loss: 1.509140968322754 Norm loss: 0.0
ATTN untarget: bbox loss: 922.3425903320312 Class loss: 1.5077557563781738 Norm loss: 0.0
ATTN untarget: bbox loss: 922.3425903320312 Class loss: 1.5079389810562134 Norm loss: 0.0
ATTN untarget: bbox loss: 922.3425903320312 Class loss: 1.5079357624053955 Norm loss: 0.0
ATTN untarget: bbox loss: 922.3425903320312 Class loss: 1.5079398155212402 Norm loss: 0.0
ATTN untarget: bbox loss: 922.3425903320312 Class loss: 1.5079385042190552 Norm loss: 0.0
[10/22 15:54:56 d2.evaluation.evaluator]: Inference done 4156/5000. Dataloading: 0.0166 s/iter. Inference: 0.0132 s/iter. Eval: 0.0000 s/iter. Total: 0.0298 s/iter. ETA=0:00:25
ATTN untarget: bbox loss: 1229.0032958984375 Class loss: 1.3575682640075684 Norm loss: 0.0
ATTN untarget: bbox loss: 1229.0032958984375 Class loss: 1.3575682640075684 Norm loss: 0.0
ATTN untarget: bbox loss: 1229.0032958984375 Class loss: 1.3575682640075684 Norm loss: 0.0
ATTN untarget: bbox loss: 1229.0032958984375 Class loss: 1.3575682640075684 Norm loss: 0.0
ATTN untarget: bbox loss: 1229.0032958984375 Class loss: 1.3575682640075684 Norm loss: 0.0
ATTN untarget: bbox loss: 1229.0032958984375 Class loss: 1.3575682640075684 Norm loss: 0.0
ATTN untarget: bbox loss: 1229.0032958984375 Class loss: 1.3575682640075684 Norm loss: 0.0
ATTN untarget: bbox loss: 1229.0032958984375 Class loss: 1.3575682640075684 Norm loss: 0.0
ATTN untarget: bbox loss: 1229.0032958984375 Class loss: 1.3575682640075684 Norm loss: 0.0
ATTN untarget: bbox loss: 1229.0032958984375 Class loss: 1.3575682640075684 Norm loss: 0.0
ATTN untarget: bbox loss: 606.9071655273438 Class loss: 1.2764123678207397 Norm loss: 0.0
ATTN untarget: bbox loss: 606.9071655273438 Class loss: 1.2767876386642456 Norm loss: 0.0
ATTN untarget: bbox loss: 606.9071655273438 Class loss: 1.2767525911331177 Norm loss: 0.0
ATTN untarget: bbox loss: 606.9071655273438 Class loss: 1.2764462232589722 Norm loss: 0.0
ATTN untarget: bbox loss: 606.9071655273438 Class loss: 1.2767834663391113 Norm loss: 0.0
ATTN untarget: bbox loss: 606.9071655273438 Class loss: 1.2767870426177979 Norm loss: 0.0
ATTN untarget: bbox loss: 606.9071655273438 Class loss: 1.2767834663391113 Norm loss: 0.0
ATTN untarget: bbox loss: 606.9071655273438 Class loss: 1.2767870426177979 Norm loss: 0.0
ATTN untarget: bbox loss: 606.9071655273438 Class loss: 1.2767834663391113 Norm loss: 0.0
ATTN untarget: bbox loss: 606.9071655273438 Class loss: 1.2767870426177979 Norm loss: 0.0
[10/22 15:55:12 d2.evaluation.evaluator]: Inference done 4893/5000. Dataloading: 0.0166 s/iter. Inference: 0.0120 s/iter. Eval: 0.0000 s/iter. Total: 0.0285 s/iter. ETA=0:00:03
[10/22 15:55:14 d2.evaluation.evaluator]: Total inference time: 0:02:21.239047 (0.028276 s / iter per device, on 1 devices)
[10/22 15:55:14 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:58 (0.011736 s / iter per device, on 1 devices)
[10/22 15:55:14 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[10/22 15:55:14 d2.evaluation.coco_evaluation]: Saving results to ./output/dino_r50_4scale_12ep/coco_instances_results.json
[10/22 15:55:14 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
[10/22 15:55:14 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[10/22 15:55:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 3.07 seconds.
[10/22 15:55:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[10/22 15:55:17 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.23 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
[10/22 15:55:17 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.003 | 0.009  | 0.004  | 0.000 | 0.000 | 0.003 |
[10/22 15:55:17 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 0.036 | bicycle      | 0.000 | car            | 0.000 |
| motorcycle    | 0.000 | airplane     | 0.000 | bus            | 0.000 |
| train         | 0.000 | truck        | 0.000 | boat           | 0.000 |
| traffic light | 0.000 | fire hydrant | 0.000 | stop sign      | 0.000 |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000 |
| cat           | 0.000 | dog          | 0.000 | horse          | 0.000 |
| sheep         | 0.000 | cow          | 0.000 | elephant       | 0.000 |
| bear          | 0.000 | zebra        | 0.000 | giraffe        | 0.000 |
| backpack      | 0.000 | umbrella     | 0.000 | handbag        | 0.000 |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.000 |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.000 |
| kite          | 0.000 | baseball bat | 0.000 | baseball glove | 0.000 |
| skateboard    | 0.000 | surfboard    | 0.000 | tennis racket  | 0.000 |
| bottle        | 0.000 | wine glass   | 0.000 | cup            | 0.000 |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |
| bowl          | 0.000 | banana       | 0.000 | apple          | 0.000 |
| sandwich      | 0.085 | orange       | 0.000 | broccoli       | 0.000 |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.008 |
| donut         | 0.009 | cake         | 0.000 | chair          | 0.000 |
| couch         | 0.000 | potted plant | 0.000 | bed            | 0.000 |
| dining table  | 0.099 | toilet       | 0.000 | tv             | 0.000 |
| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.000 |
| keyboard      | 0.000 | cell phone   | 0.000 | microwave      | 0.000 |
| oven          | 0.000 | toaster      | 0.000 | sink           | 0.000 |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 0.000 |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |


------- Similarity and Timing Metrics -------
Average Attack Time: 5.88
Average L2 Norm: nan
Max Difference in Images: 0.0078
------------------------------------------------


[10/22 15:55:17 d2.evaluation.testing]: copypaste: Task: bbox
[10/22 15:55:17 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[10/22 15:55:17 d2.evaluation.testing]: copypaste: 0.0030,0.0090,0.0040,0.0000,0.0000,0.0031
OrderedDict({'bbox': {'AP': 0.0029535182160882792, 'AP50': 0.009001930412821503, 'AP75': 0.00399358544877044, 'APs': 0.0, 'APm': 0.0, 'APl': 0.0030663593682562747, 'AP-person': 0.035788880556861837, 'AP-bicycle': 0.0, 'AP-car': 0.0, 'AP-motorcycle': 0.0, 'AP-airplane': 0.0, 'AP-bus': 0.0, 'AP-train': 0.0, 'AP-truck': 0.0, 'AP-boat': 0.0, 'AP-traffic light': 0.0, 'AP-fire hydrant': 0.0, 'AP-stop sign': 0.0, 'AP-parking meter': 0.0, 'AP-bench': 0.0, 'AP-bird': 0.0, 'AP-cat': 0.0, 'AP-dog': 0.0, 'AP-horse': 0.0, 'AP-sheep': 0.0, 'AP-cow': 0.0, 'AP-elephant': 0.0, 'AP-bear': 0.0, 'AP-zebra': 0.0, 'AP-giraffe': 0.0, 'AP-backpack': 0.0, 'AP-umbrella': 0.0, 'AP-handbag': 0.0, 'AP-tie': 0.0, 'AP-suitcase': 0.0, 'AP-frisbee': 0.0, 'AP-skis': 0.0, 'AP-snowboard': 0.0, 'AP-sports ball': 0.0, 'AP-kite': 0.0, 'AP-baseball bat': 0.0, 'AP-baseball glove': 0.0, 'AP-skateboard': 0.0, 'AP-surfboard': 0.0, 'AP-tennis racket': 0.0, 'AP-bottle': 0.0, 'AP-wine glass': 0.0, 'AP-cup': 0.0, 'AP-fork': 0.0, 'AP-knife': 0.0, 'AP-spoon': 0.0, 'AP-bowl': 0.0, 'AP-banana': 0.0, 'AP-apple': 0.0, 'AP-sandwich': 0.08486562942008485, 'AP-orange': 0.0, 'AP-broccoli': 0.0, 'AP-carrot': 0.0, 'AP-hot dog': 0.0, 'AP-pizza': 0.007616146230007617, 'AP-donut': 0.009000900090009001, 'AP-cake': 0.0, 'AP-chair': 0.0, 'AP-couch': 0.0, 'AP-potted plant': 0.0, 'AP-bed': 0.0, 'AP-dining table': 0.09900990099009899, 'AP-toilet': 0.0, 'AP-tv': 0.0, 'AP-laptop': 0.0, 'AP-mouse': 0.0, 'AP-remote': 0.0, 'AP-keyboard': 0.0, 'AP-cell phone': 0.0, 'AP-microwave': 0.0, 'AP-oven': 0.0, 'AP-toaster': 0.0, 'AP-sink': 0.0, 'AP-refrigerator': 0.0, 'AP-book': 0.0, 'AP-clock': 0.0, 'AP-vase': 0.0, 'AP-scissors': 0.0, 'AP-teddy bear': 0.0, 'AP-hair drier': 0.0, 'AP-toothbrush': 0.0}})
---------------------------------------
Begin Slurm Epilog: Oct-22-2024 15:55:22
Job ID:        879568
Array Job ID:  _4294967294
User ID:       zyahn3
Account:       scs
Job name:      TOG_Plus_R50
Resources:     cpu=1,gres/gpu:a100=1,mem=128G,node=1
Rsrc Used:     cput=00:03:10,vmem=0,walltime=00:03:10,mem=2709280K,energy_used=0
Partition:     coc-gpu
Nodes:         atl1-1-03-007-35-0
---------------------------------------
