[09/27 11:59:53.461]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 11:59:53.461]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 11:59:53.462]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 11:59:53.462]: world size: 1
[09/27 11:59:53.462]: rank: 0
[09/27 11:59:53.462]: local_rank: None
[09/27 11:59:53.462]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:00:24.519]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:00:24.520]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:00:24.521]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:00:24.521]: world size: 1
[09/27 12:00:24.521]: rank: 0
[09/27 12:00:24.521]: local_rank: None
[09/27 12:00:24.521]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:06:03.156]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:06:03.157]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:06:03.158]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:06:03.158]: world size: 1
[09/27 12:06:03.158]: rank: 0
[09/27 12:06:03.158]: local_rank: None
[09/27 12:06:03.158]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:07:29.573]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:07:29.573]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:07:29.575]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:07:29.575]: world size: 1
[09/27 12:07:29.575]: rank: 0
[09/27 12:07:29.575]: local_rank: None
[09/27 12:07:29.575]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:08:29.520]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:08:29.520]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:08:29.521]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:08:29.521]: world size: 1
[09/27 12:08:29.521]: rank: 0
[09/27 12:08:29.521]: local_rank: None
[09/27 12:08:29.521]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:08:44.752]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:08:44.752]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:08:44.753]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:08:44.753]: world size: 1
[09/27 12:08:44.753]: rank: 0
[09/27 12:08:44.753]: local_rank: None
[09/27 12:08:44.754]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:09:22.135]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:09:22.136]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:09:22.137]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:09:22.137]: world size: 1
[09/27 12:09:22.137]: rank: 0
[09/27 12:09:22.137]: local_rank: None
[09/27 12:09:22.137]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:10:01.030]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:10:01.030]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:10:01.031]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:10:01.032]: world size: 1
[09/27 12:10:01.032]: rank: 0
[09/27 12:10:01.032]: local_rank: None
[09/27 12:10:01.032]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:10:25.693]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:10:25.693]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:10:25.694]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:10:25.695]: world size: 1
[09/27 12:10:25.695]: rank: 0
[09/27 12:10:25.695]: local_rank: None
[09/27 12:10:25.695]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:10:48.388]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:10:48.388]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:10:48.389]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:10:48.389]: world size: 1
[09/27 12:10:48.389]: rank: 0
[09/27 12:10:48.389]: local_rank: None
[09/27 12:10:48.389]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:11:10.930]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:11:10.930]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:11:10.942]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:11:10.942]: world size: 1
[09/27 12:11:10.942]: rank: 0
[09/27 12:11:10.942]: local_rank: None
[09/27 12:11:10.942]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:11:33.575]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:11:33.575]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:11:33.576]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:11:33.576]: world size: 1
[09/27 12:11:33.576]: rank: 0
[09/27 12:11:33.576]: local_rank: None
[09/27 12:11:33.576]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:12:41.404]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:12:41.404]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:12:41.405]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:12:41.405]: world size: 1
[09/27 12:12:41.405]: rank: 0
[09/27 12:12:41.405]: local_rank: None
[09/27 12:12:41.405]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:17:02.518]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:17:02.518]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:17:02.519]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:17:02.519]: world size: 1
[09/27 12:17:02.519]: rank: 0
[09/27 12:17:02.519]: local_rank: None
[09/27 12:17:02.519]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:17:25.228]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:17:25.228]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:17:25.229]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:17:25.229]: world size: 1
[09/27 12:17:25.229]: rank: 0
[09/27 12:17:25.229]: local_rank: None
[09/27 12:17:25.229]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:17:41.713]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:17:41.714]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:17:41.715]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:17:41.715]: world size: 1
[09/27 12:17:41.715]: rank: 0
[09/27 12:17:41.715]: local_rank: None
[09/27 12:17:41.715]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:17:43.454]: number of params:46670782
[09/27 12:17:43.456]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 12:20:00.774]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:20:00.774]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:20:00.775]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:20:00.775]: world size: 1
[09/27 12:20:00.775]: rank: 0
[09/27 12:20:00.775]: local_rank: None
[09/27 12:20:00.775]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:20:01.934]: number of params:46670782
[09/27 12:20:01.935]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 12:32:30.359]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:32:30.371]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.path --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:32:30.373]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:32:30.373]: world size: 1
[09/27 12:32:30.373]: rank: 0
[09/27 12:32:30.373]: local_rank: None
[09/27 12:32:30.373]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.path', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:32:35.845]: number of params:46670782
[09/27 12:32:35.847]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 12:34:11.999]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:34:11.999]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:34:12.000]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:34:12.000]: world size: 1
[09/27 12:34:12.000]: rank: 0
[09/27 12:34:12.000]: local_rank: None
[09/27 12:34:12.000]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:34:13.160]: number of params:46670782
[09/27 12:34:13.162]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 12:34:51.687]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:34:51.687]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:34:51.688]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:34:51.689]: world size: 1
[09/27 12:34:51.689]: rank: 0
[09/27 12:34:51.689]: local_rank: None
[09/27 12:34:51.689]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:34:52.906]: number of params:46670782
[09/27 12:34:52.907]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 12:36:01.751]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:36:01.751]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:36:01.752]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:36:01.752]: world size: 1
[09/27 12:36:01.752]: rank: 0
[09/27 12:36:01.752]: local_rank: None
[09/27 12:36:01.752]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:36:02.921]: number of params:46670782
[09/27 12:36:02.922]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 12:36:54.846]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:36:54.847]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:36:54.848]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:36:54.848]: world size: 1
[09/27 12:36:54.848]: rank: 0
[09/27 12:36:54.848]: local_rank: None
[09/27 12:36:54.848]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:36:56.021]: number of params:46670782
[09/27 12:36:56.022]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 12:38:56.055]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:38:56.055]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:38:56.056]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:38:56.056]: world size: 1
[09/27 12:38:56.056]: rank: 0
[09/27 12:38:56.056]: local_rank: None
[09/27 12:38:56.056]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:38:57.221]: number of params:46670782
[09/27 12:38:57.223]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 12:41:04.449]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:41:04.449]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:41:04.450]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:41:04.450]: world size: 1
[09/27 12:41:04.450]: rank: 0
[09/27 12:41:04.450]: local_rank: None
[09/27 12:41:04.450]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:41:05.619]: number of params:46670782
[09/27 12:41:05.620]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 12:42:17.049]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:42:17.050]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:42:17.051]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:42:17.051]: world size: 1
[09/27 12:42:17.051]: rank: 0
[09/27 12:42:17.051]: local_rank: None
[09/27 12:42:17.051]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:42:18.219]: number of params:46670782
[09/27 12:42:18.221]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 12:43:07.672]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:43:07.672]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:43:07.673]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:43:07.673]: world size: 1
[09/27 12:43:07.673]: rank: 0
[09/27 12:43:07.674]: local_rank: None
[09/27 12:43:07.674]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:43:08.841]: number of params:46670782
[09/27 12:43:08.842]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 12:52:11.319]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:52:11.319]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:52:11.320]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:52:11.320]: world size: 1
[09/27 12:52:11.320]: rank: 0
[09/27 12:52:11.321]: local_rank: None
[09/27 12:52:11.321]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:52:26.853]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:52:26.853]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:52:26.854]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:52:26.854]: world size: 1
[09/27 12:52:26.854]: rank: 0
[09/27 12:52:26.854]: local_rank: None
[09/27 12:52:26.854]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:52:28.037]: number of params:46670782
[09/27 12:52:28.038]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 12:55:29.327]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:55:29.327]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:55:29.328]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:55:29.329]: world size: 1
[09/27 12:55:29.329]: rank: 0
[09/27 12:55:29.329]: local_rank: None
[09/27 12:55:29.329]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:55:30.494]: number of params:46670782
[09/27 12:55:30.496]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 12:56:20.600]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:56:20.600]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:56:20.601]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:56:20.601]: world size: 1
[09/27 12:56:20.601]: rank: 0
[09/27 12:56:20.601]: local_rank: None
[09/27 12:56:20.601]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:56:21.768]: number of params:46670782
[09/27 12:56:21.769]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 12:57:48.121]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:57:48.121]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:57:48.122]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:57:48.122]: world size: 1
[09/27 12:57:48.122]: rank: 0
[09/27 12:57:48.122]: local_rank: None
[09/27 12:57:48.123]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:57:49.290]: number of params:46670782
[09/27 12:57:49.292]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 12:59:26.998]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 12:59:26.999]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 12:59:27.000]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 12:59:27.000]: world size: 1
[09/27 12:59:27.000]: rank: 0
[09/27 12:59:27.000]: local_rank: None
[09/27 12:59:27.000]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 12:59:28.171]: number of params:46670782
[09/27 12:59:28.172]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 13:00:39.450]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 13:00:39.450]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 13:00:39.451]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 13:00:39.451]: world size: 1
[09/27 13:00:39.451]: rank: 0
[09/27 13:00:39.451]: local_rank: None
[09/27 13:00:39.451]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 13:00:40.620]: number of params:46670782
[09/27 13:00:40.621]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 13:10:19.379]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 13:10:19.380]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/detr-r101.pth --attack none --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 13:10:19.381]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 13:10:19.381]: world size: 1
[09/27 13:10:19.382]: rank: 0
[09/27 13:10:19.382]: local_rank: None
[09/27 13:10:19.382]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/detr-r101.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='none', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 13:10:20.636]: number of params:46670782
[09/27 13:10:20.638]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 13:11:25.861]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 13:11:25.861]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack none --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 13:11:25.862]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 13:11:25.862]: world size: 1
[09/27 13:11:25.862]: rank: 0
[09/27 13:11:25.863]: local_rank: None
[09/27 13:11:25.863]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='none', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 13:11:27.111]: number of params:46670782
[09/27 13:11:27.113]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 13:13:43.100]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 13:13:43.100]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 13:13:43.102]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 13:13:43.103]: world size: 1
[09/27 13:13:43.103]: rank: 0
[09/27 13:13:43.103]: local_rank: None
[09/27 13:13:43.103]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 13:13:51.149]: number of params:46670782
[09/27 13:13:51.150]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 13:29:47.008]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 13:29:47.009]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 13:29:47.011]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 13:29:47.011]: world size: 1
[09/27 13:29:47.011]: rank: 0
[09/27 13:29:47.011]: local_rank: None
[09/27 13:29:47.011]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 13:29:48.233]: number of params:46670782
[09/27 13:29:48.234]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 13:30:23.945]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 13:30:23.945]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 13:30:23.946]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 13:30:23.947]: world size: 1
[09/27 13:30:23.947]: rank: 0
[09/27 13:30:23.947]: local_rank: None
[09/27 13:30:23.947]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 13:30:25.117]: number of params:46670782
[09/27 13:30:25.118]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 13:30:53.892]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 13:30:53.892]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 13:30:53.893]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 13:30:53.893]: world size: 1
[09/27 13:30:53.893]: rank: 0
[09/27 13:30:53.893]: local_rank: None
[09/27 13:30:53.893]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 13:30:55.069]: number of params:46670782
[09/27 13:30:55.070]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 13:37:52.768]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 13:37:52.768]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 13:37:52.769]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 13:37:52.769]: world size: 1
[09/27 13:37:52.769]: rank: 0
[09/27 13:37:52.769]: local_rank: None
[09/27 13:37:52.769]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 13:37:53.944]: number of params:46670782
[09/27 13:37:53.945]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 13:40:09.763]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 13:40:09.763]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 13:40:09.764]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 13:40:09.764]: world size: 1
[09/27 13:40:09.764]: rank: 0
[09/27 13:40:09.764]: local_rank: None
[09/27 13:40:09.764]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 13:40:10.926]: number of params:46670782
[09/27 13:40:10.927]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 13:44:47.481]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 13:44:47.481]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 13:44:47.482]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 13:44:47.483]: world size: 1
[09/27 13:44:47.483]: rank: 0
[09/27 13:44:47.483]: local_rank: None
[09/27 13:44:47.483]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 13:44:48.652]: number of params:46670782
[09/27 13:44:48.653]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 13:46:41.861]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 13:46:41.861]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack none --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 13:46:41.862]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 13:46:41.862]: world size: 1
[09/27 13:46:41.862]: rank: 0
[09/27 13:46:41.862]: local_rank: None
[09/27 13:46:41.862]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='none', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 13:46:43.027]: number of params:46670782
[09/27 13:46:43.028]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 13:48:05.184]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 13:48:05.184]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack none --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 13:48:05.185]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 13:48:05.185]: world size: 1
[09/27 13:48:05.185]: rank: 0
[09/27 13:48:05.185]: local_rank: None
[09/27 13:48:05.185]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='none', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 13:48:06.348]: number of params:46670782
[09/27 13:48:06.349]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 13:54:29.964]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 13:54:29.965]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 13:54:29.966]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 13:54:29.966]: world size: 1
[09/27 13:54:29.966]: rank: 0
[09/27 13:54:29.966]: local_rank: None
[09/27 13:54:29.966]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 13:59:04.523]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 13:59:04.523]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 13:59:04.524]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 13:59:04.524]: world size: 1
[09/27 13:59:04.524]: rank: 0
[09/27 13:59:04.524]: local_rank: None
[09/27 13:59:04.524]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 13:59:05.684]: number of params:46670782
[09/27 13:59:05.685]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 14:02:08.180]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:02:08.180]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:02:08.181]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:02:08.181]: world size: 1
[09/27 14:02:08.181]: rank: 0
[09/27 14:02:08.181]: local_rank: None
[09/27 14:02:08.181]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:02:09.361]: number of params:46670782
[09/27 14:02:09.363]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 14:03:03.580]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:03:03.580]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:03:03.581]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:03:03.581]: world size: 1
[09/27 14:03:03.581]: rank: 0
[09/27 14:03:03.581]: local_rank: None
[09/27 14:03:03.582]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:03:04.749]: number of params:46670782
[09/27 14:03:04.751]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 14:05:04.658]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:05:04.658]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:05:04.659]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:05:04.659]: world size: 1
[09/27 14:05:04.659]: rank: 0
[09/27 14:05:04.659]: local_rank: None
[09/27 14:05:04.659]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:05:05.828]: number of params:46670782
[09/27 14:05:05.829]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 14:09:32.649]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:09:32.650]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:09:32.652]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:09:32.652]: world size: 1
[09/27 14:09:32.652]: rank: 0
[09/27 14:09:32.652]: local_rank: None
[09/27 14:09:32.653]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:09:33.862]: number of params:46670782
[09/27 14:09:33.864]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 14:12:28.833]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:12:28.833]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:12:28.835]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:12:28.835]: world size: 1
[09/27 14:12:28.835]: rank: 0
[09/27 14:12:28.835]: local_rank: None
[09/27 14:12:28.835]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:12:30.033]: number of params:46670782
[09/27 14:12:30.034]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 14:15:50.269]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:15:50.270]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:15:50.271]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:15:50.271]: world size: 1
[09/27 14:15:50.271]: rank: 0
[09/27 14:15:50.271]: local_rank: None
[09/27 14:15:50.271]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:15:51.482]: number of params:46670782
[09/27 14:15:51.483]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 14:22:15.414]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:22:15.444]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack untarget --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:22:15.446]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:22:15.447]: world size: 1
[09/27 14:22:15.447]: rank: 0
[09/27 14:22:15.447]: local_rank: None
[09/27 14:22:15.447]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untarget', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:22:23.215]: number of params:46670782
[09/27 14:22:23.218]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 14:22:28.119]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:22:28.119]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack none --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:22:28.120]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:22:28.121]: world size: 1
[09/27 14:22:28.121]: rank: 0
[09/27 14:22:28.121]: local_rank: None
[09/27 14:22:28.121]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='none', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:22:31.638]: number of params:217230066
[09/27 14:22:31.641]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 14:32:38.300]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:32:38.301]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack none --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:32:38.303]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:32:38.303]: world size: 1
[09/27 14:32:38.303]: rank: 0
[09/27 14:32:38.303]: local_rank: None
[09/27 14:32:38.304]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='none', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:32:47.444]: number of params:217230066
[09/27 14:32:47.447]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 14:35:51.870]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:35:51.870]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:35:51.872]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:35:51.872]: world size: 1
[09/27 14:35:51.872]: rank: 0
[09/27 14:35:51.872]: local_rank: None
[09/27 14:35:51.872]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:35:54.545]: number of params:46670782
[09/27 14:35:54.548]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 14:40:44.725]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:40:44.725]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:40:44.727]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:40:44.727]: world size: 1
[09/27 14:40:44.727]: rank: 0
[09/27 14:40:44.727]: local_rank: None
[09/27 14:40:44.727]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:40:46.252]: number of params:46670782
[09/27 14:40:46.254]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/27 14:43:40.218]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:43:40.218]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:43:40.219]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:43:40.219]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:43:40.221]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:43:40.221]: world size: 1
[09/27 14:43:40.221]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:43:40.221]: rank: 0
[09/27 14:43:40.221]: world size: 1
[09/27 14:43:40.221]: local_rank: None
[09/27 14:43:40.222]: rank: 0
[09/27 14:43:40.222]: local_rank: None
[09/27 14:43:40.222]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:43:40.222]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:43:50.325]: number of params:217230066
[09/27 14:43:50.328]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 14:43:50.336]: number of params:217230066
[09/27 14:43:50.339]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 14:56:57.754]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:56:57.755]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 4 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:56:57.757]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:56:57.757]: world size: 1
[09/27 14:56:57.757]: rank: 0
[09/27 14:56:57.757]: local_rank: None
[09/27 14:56:57.757]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:56:57.759]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:56:57.759]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 4 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:56:57.759]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:56:57.760]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 4 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:56:57.760]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:56:57.760]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 4 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:56:57.760]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:56:57.760]: world size: 1
[09/27 14:56:57.760]: rank: 0
[09/27 14:56:57.760]: local_rank: None
[09/27 14:56:57.761]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:56:57.761]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:56:57.761]: world size: 1
[09/27 14:56:57.761]: rank: 0
[09/27 14:56:57.761]: local_rank: None
[09/27 14:56:57.761]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:56:57.761]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:56:57.761]: world size: 1
[09/27 14:56:57.761]: rank: 0
[09/27 14:56:57.761]: local_rank: None
[09/27 14:56:57.761]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:57:00.932]: number of params:217230066
[09/27 14:57:00.935]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 14:57:00.943]: number of params:217230066
[09/27 14:57:00.946]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 14:57:00.950]: number of params:217230066
[09/27 14:57:00.952]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 14:57:00.965]: number of params:217230066
[09/27 14:57:00.968]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 14:57:47.512]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:57:47.512]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 4 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:57:47.512]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:57:47.512]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 4 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:57:47.513]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:57:47.513]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 4 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:57:47.513]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:57:47.513]: world size: 1
[09/27 14:57:47.513]: rank: 0
[09/27 14:57:47.513]: local_rank: None
[09/27 14:57:47.513]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:57:47.514]: world size: 1
[09/27 14:57:47.514]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:57:47.514]: rank: 0
[09/27 14:57:47.514]: local_rank: None
[09/27 14:57:47.514]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:57:47.515]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:57:47.515]: world size: 1
[09/27 14:57:47.515]: rank: 0
[09/27 14:57:47.515]: local_rank: None
[09/27 14:57:47.515]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:57:47.519]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:57:47.519]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 4 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:57:47.520]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:57:47.520]: world size: 1
[09/27 14:57:47.520]: rank: 0
[09/27 14:57:47.520]: local_rank: None
[09/27 14:57:47.521]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:57:50.512]: number of params:217230066
[09/27 14:57:50.514]: number of params:217230066
[09/27 14:57:50.515]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 14:57:50.520]: number of params:217230066
[09/27 14:57:50.521]: number of params:217230066
[09/27 14:57:50.522]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 14:57:50.523]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 14:57:50.523]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 14:59:02.180]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:59:02.180]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 4 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:59:02.181]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:59:02.181]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 4 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:59:02.181]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:59:02.181]: world size: 1
[09/27 14:59:02.181]: rank: 0
[09/27 14:59:02.181]: local_rank: None
[09/27 14:59:02.181]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:59:02.182]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:59:02.183]: world size: 1
[09/27 14:59:02.183]: rank: 0
[09/27 14:59:02.183]: local_rank: None
[09/27 14:59:02.183]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:59:02.199]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:59:02.199]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 4 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:59:02.200]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 14:59:02.200]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 4 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 14:59:02.200]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:59:02.200]: world size: 1
[09/27 14:59:02.200]: rank: 0
[09/27 14:59:02.200]: local_rank: None
[09/27 14:59:02.201]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:59:02.202]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 14:59:02.202]: world size: 1
[09/27 14:59:02.202]: rank: 0
[09/27 14:59:02.202]: local_rank: None
[09/27 14:59:02.202]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 14:59:05.196]: number of params:217230066
[09/27 14:59:05.199]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 14:59:05.215]: number of params:217230066
[09/27 14:59:05.218]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 14:59:05.221]: number of params:217230066
[09/27 14:59:05.221]: number of params:217230066
[09/27 14:59:05.223]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 14:59:05.223]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 15:02:59.994]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 15:02:59.994]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 15:02:59.995]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 2 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 15:02:59.996]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 2 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 15:02:59.997]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 15:02:59.997]: world size: 1
[09/27 15:02:59.998]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 15:02:59.998]: world size: 1
[09/27 15:02:59.998]: rank: 0
[09/27 15:02:59.998]: local_rank: None
[09/27 15:02:59.998]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 15:02:59.998]: rank: 0
[09/27 15:02:59.999]: local_rank: None
[09/27 15:02:59.999]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 15:03:19.920]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 15:03:19.921]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 1 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 15:03:19.922]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 15:03:19.923]: world size: 1
[09/27 15:03:19.923]: rank: 0
[09/27 15:03:19.923]: local_rank: None
[09/27 15:03:19.923]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=1, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 16:35:14.952]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 16:35:14.952]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 16:35:14.953]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 2 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 16:35:14.953]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 2 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 16:35:14.954]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 16:35:14.954]: world size: 1
[09/27 16:35:14.954]: rank: 0
[09/27 16:35:14.954]: local_rank: None
[09/27 16:35:14.954]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 16:35:14.954]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 16:35:14.955]: world size: 1
[09/27 16:35:14.955]: rank: 0
[09/27 16:35:14.955]: local_rank: None
[09/27 16:35:14.955]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 16:35:25.054]: number of params:217230066
[09/27 16:35:25.057]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 16:35:25.069]: number of params:217230066
[09/27 16:35:25.072]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 16:37:37.539]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 16:37:37.539]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 2 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 16:37:37.539]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 16:37:37.540]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 2 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 16:37:37.540]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 16:37:37.540]: world size: 1
[09/27 16:37:37.540]: rank: 0
[09/27 16:37:37.541]: local_rank: None
[09/27 16:37:37.541]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 16:37:37.541]: world size: 1
[09/27 16:37:37.541]: rank: 0
[09/27 16:37:37.541]: local_rank: None
[09/27 16:37:37.541]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 16:37:37.541]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 16:37:40.617]: number of params:217230066
[09/27 16:37:40.621]: number of params:217230066
[09/27 16:37:40.623]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 16:37:40.620]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 16:43:46.943]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 16:43:46.943]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 16:43:46.961]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 2 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 16:43:46.961]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 2 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 16:43:46.963]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 16:43:46.964]: world size: 1
[09/27 16:43:46.964]: rank: 0
[09/27 16:43:46.964]: local_rank: None
[09/27 16:43:46.963]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 16:43:46.964]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 16:43:46.964]: world size: 1
[09/27 16:43:46.964]: rank: 0
[09/27 16:43:46.964]: local_rank: None
[09/27 16:43:46.964]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 16:43:57.979]: number of params:217230066
[09/27 16:43:57.980]: number of params:217230066
[09/27 16:43:57.983]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 16:43:57.982]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 16:57:23.147]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 16:57:23.148]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 16:57:23.157]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 2 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 16:57:23.157]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 2 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 16:57:23.158]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 16:57:23.158]: world size: 1
[09/27 16:57:23.158]: rank: 0
[09/27 16:57:23.158]: local_rank: None
[09/27 16:57:23.158]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 16:57:23.159]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 16:57:23.159]: world size: 1
[09/27 16:57:23.159]: rank: 0
[09/27 16:57:23.159]: local_rank: None
[09/27 16:57:23.159]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 16:57:26.214]: number of params:217230066
[09/27 16:57:26.215]: number of params:217230066
[09/27 16:57:26.217]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 16:57:26.222]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 17:00:36.147]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 17:00:36.148]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 17:00:36.149]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 2 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 17:00:36.149]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 2 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 17:00:36.151]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 17:00:36.151]: world size: 1
[09/27 17:00:36.151]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 17:00:36.151]: rank: 0
[09/27 17:00:36.151]: world size: 1
[09/27 17:00:36.151]: rank: 0
[09/27 17:00:36.151]: local_rank: None
[09/27 17:00:36.151]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 17:00:36.151]: local_rank: None
[09/27 17:00:36.152]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=2, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 17:00:39.606]: number of params:217230066
[09/27 17:00:39.609]: number of params:217230066
[09/27 17:00:39.612]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 17:00:39.609]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 17:18:12.586]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 17:18:12.602]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 17:18:12.602]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 17:18:12.603]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 17:18:12.605]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 17:18:12.605]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 17:18:12.605]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 17:18:12.605]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 17:18:12.606]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 17:18:12.606]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 17:18:12.606]: world size: 1
[09/27 17:18:12.606]: world size: 1
[09/27 17:18:12.606]: rank: 0
[09/27 17:18:12.606]: rank: 0
[09/27 17:18:12.606]: local_rank: None
[09/27 17:18:12.606]: local_rank: None
[09/27 17:18:12.606]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 17:18:12.607]: world size: 1
[09/27 17:18:12.607]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 17:18:12.607]: rank: 0
[09/27 17:18:12.607]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 17:18:12.607]: local_rank: None
[09/27 17:18:12.607]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 17:18:12.607]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 17:18:12.607]: world size: 1
[09/27 17:18:12.607]: rank: 0
[09/27 17:18:12.607]: local_rank: None
[09/27 17:18:12.607]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 17:18:12.617]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 17:18:12.618]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 17:18:12.618]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 17:18:12.618]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 17:18:12.618]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 17:18:12.618]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 17:18:12.619]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 17:18:12.619]: world size: 1
[09/27 17:18:12.619]: rank: 0
[09/27 17:18:12.619]: local_rank: None
[09/27 17:18:12.619]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 17:18:12.619]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 17:18:12.619]: world size: 1
[09/27 17:18:12.619]: rank: 0
[09/27 17:18:12.619]: local_rank: None
[09/27 17:18:12.619]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 17:18:12.619]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 17:18:12.619]: world size: 1
[09/27 17:18:12.619]: rank: 0
[09/27 17:18:12.619]: local_rank: None
[09/27 17:18:12.620]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 17:18:12.644]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 17:18:12.644]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 17:18:12.645]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 17:18:12.645]: world size: 1
[09/27 17:18:12.645]: rank: 0
[09/27 17:18:12.645]: local_rank: None
[09/27 17:18:12.645]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 17:18:16.967]: number of params:217230066
[09/27 17:18:16.970]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 17:18:16.971]: number of params:217230066
[09/27 17:18:16.974]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 17:18:16.974]: number of params:217230066
[09/27 17:18:16.976]: number of params:217230066
[09/27 17:18:16.978]: number of params:217230066
[09/27 17:18:16.977]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 17:18:16.979]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 17:18:16.982]: number of params:217230066
[09/27 17:18:16.981]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 17:18:16.984]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 17:18:16.993]: number of params:217230066
[09/27 17:18:16.997]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 17:18:17.013]: number of params:217230066
[09/27 17:18:17.016]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 17:19:26.081]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 17:19:26.081]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 17:19:26.081]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 17:19:26.081]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 4 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 17:19:26.081]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 17:19:26.081]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 4 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 17:19:26.081]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 4 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 17:19:26.081]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 4 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 17:19:26.082]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 17:19:26.082]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 17:19:26.082]: world size: 1
[09/27 17:19:26.082]: world size: 1
[09/27 17:19:26.082]: rank: 0
[09/27 17:19:26.082]: rank: 0
[09/27 17:19:26.082]: local_rank: None
[09/27 17:19:26.082]: local_rank: None
[09/27 17:19:26.082]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 17:19:26.083]: world size: 1
[09/27 17:19:26.083]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 17:19:26.083]: rank: 0
[09/27 17:19:26.083]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 17:19:26.083]: local_rank: None
[09/27 17:19:26.083]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 17:19:26.082]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 17:19:26.083]: world size: 1
[09/27 17:19:26.083]: rank: 0
[09/27 17:19:26.083]: local_rank: None
[09/27 17:19:26.083]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=4, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 17:19:29.712]: number of params:217230066
[09/27 17:19:29.715]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 17:19:29.723]: number of params:217230066
[09/27 17:19:29.725]: number of params:217230066
[09/27 17:19:29.726]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 17:19:29.727]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 17:19:29.739]: number of params:217230066
[09/27 17:19:29.743]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 17:25:03.190]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 17:25:03.191]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 17:25:03.193]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 17:25:03.193]: world size: 1
[09/27 17:25:03.193]: rank: 0
[09/27 17:25:03.193]: local_rank: None
[09/27 17:25:03.193]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 17:25:11.215]: number of params:217230066
[09/27 17:25:11.217]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 17:36:46.178]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 17:36:46.178]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 17:36:46.179]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 12 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 17:36:46.179]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 12 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 17:36:46.181]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 17:36:46.181]: world size: 1
[09/27 17:36:46.181]: rank: 0
[09/27 17:36:46.181]: local_rank: None
[09/27 17:36:46.181]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=12, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 17:36:46.181]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 17:36:46.181]: world size: 1
[09/27 17:36:46.181]: rank: 0
[09/27 17:36:46.182]: local_rank: None
[09/27 17:36:46.182]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=12, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 17:36:49.269]: number of params:217230066
[09/27 17:36:49.272]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 17:36:49.281]: number of params:217230066
[09/27 17:36:49.284]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 17:39:30.897]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 17:39:30.898]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 16 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 17:39:30.912]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 17:39:30.912]: world size: 1
[09/27 17:39:30.912]: rank: 0
[09/27 17:39:30.912]: local_rank: None
[09/27 17:39:30.913]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=16, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 17:39:33.879]: number of params:217230066
[09/27 17:39:33.882]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 18:52:13.356]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 18:52:13.367]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 18:52:13.369]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 18:52:13.369]: world size: 1
[09/27 18:52:13.369]: rank: 0
[09/27 18:52:13.369]: local_rank: None
[09/27 18:52:13.370]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 18:52:21.627]: number of params:217230066
[09/27 18:52:21.629]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/27 19:05:51.406]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/27 19:05:51.407]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/27 19:05:51.408]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/27 19:05:51.409]: world size: 1
[09/27 19:05:51.409]: rank: 0
[09/27 19:05:51.409]: local_rank: None
[09/27 19:05:51.409]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/27 19:05:53.508]: number of params:217230066
[09/27 19:05:53.511]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/28 01:52:03.619]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/28 01:52:03.621]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/28 01:52:03.623]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/28 01:52:03.623]: world size: 1
[09/28 01:52:03.623]: rank: 0
[09/28 01:52:03.623]: local_rank: None
[09/28 01:52:03.623]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/28 01:52:16.532]: number of params:217230066
[09/28 01:52:16.534]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/28 10:43:17.178]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/28 10:43:17.179]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/28 10:43:17.181]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/28 10:43:17.181]: world size: 1
[09/28 10:43:17.181]: rank: 0
[09/28 10:43:17.181]: local_rank: None
[09/28 10:43:17.181]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/28 10:43:25.592]: number of params:217230066
[09/28 10:43:25.595]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/28 10:57:01.381]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/28 10:57:01.383]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/28 10:57:01.385]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/28 10:57:01.385]: world size: 1
[09/28 10:57:01.385]: rank: 0
[09/28 10:57:01.385]: local_rank: None
[09/28 10:57:01.385]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/28 10:57:12.037]: number of params:217230066
[09/28 10:57:12.039]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/28 18:09:18.291]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/28 18:09:18.307]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/28 18:09:18.308]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/28 18:09:18.309]: world size: 1
[09/28 18:09:18.309]: rank: 0
[09/28 18:09:18.309]: local_rank: None
[09/28 18:09:18.309]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/28 18:09:27.890]: number of params:217230066
[09/28 18:09:27.893]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/28 23:04:07.898]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/28 23:04:07.900]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/28 23:04:07.901]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/28 23:04:07.901]: world size: 1
[09/28 23:04:07.901]: rank: 0
[09/28 23:04:07.901]: local_rank: None
[09/28 23:04:07.901]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/28 23:04:17.724]: number of params:217230066
[09/28 23:04:17.726]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/30 12:45:33.656]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/30 12:45:33.677]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/30 12:45:33.678]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/30 12:45:33.679]: world size: 1
[09/30 12:45:33.679]: rank: 0
[09/30 12:45:33.679]: local_rank: None
[09/30 12:45:33.679]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/30 12:45:39.400]: number of params:46670782
[09/30 12:45:39.401]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/30 12:48:15.025]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/30 12:48:15.025]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/30 12:48:15.026]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/30 12:48:15.026]: world size: 1
[09/30 12:48:15.027]: rank: 0
[09/30 12:48:15.027]: local_rank: None
[09/30 12:48:15.027]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/30 12:48:16.389]: number of params:46670782
[09/30 12:48:16.390]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/30 12:48:41.524]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/30 12:48:41.525]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/30 12:48:41.526]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/30 12:48:41.526]: world size: 1
[09/30 12:48:41.526]: rank: 0
[09/30 12:48:41.526]: local_rank: None
[09/30 12:48:41.526]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/30 12:48:43.755]: number of params:217230066
[09/30 12:48:43.757]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/30 12:53:20.499]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/30 12:53:20.499]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/30 12:53:20.500]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/30 12:53:20.500]: world size: 1
[09/30 12:53:20.500]: rank: 0
[09/30 12:53:20.501]: local_rank: None
[09/30 12:53:20.501]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/30 12:53:22.568]: number of params:217230066
[09/30 12:53:22.570]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/30 12:57:36.211]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/30 12:57:36.212]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/30 12:57:36.214]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/30 12:57:36.215]: world size: 1
[09/30 12:57:36.215]: rank: 0
[09/30 12:57:36.215]: local_rank: None
[09/30 12:57:36.215]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/30 12:57:44.789]: number of params:217230066
[09/30 12:57:44.791]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/30 12:59:35.800]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/30 12:59:35.801]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/30 12:59:35.802]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/30 12:59:35.802]: world size: 1
[09/30 12:59:35.802]: rank: 0
[09/30 12:59:35.802]: local_rank: None
[09/30 12:59:35.803]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/30 12:59:37.922]: number of params:217230066
[09/30 12:59:37.925]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/30 13:01:01.369]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/30 13:01:01.370]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/30 13:01:01.388]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/30 13:01:01.389]: world size: 1
[09/30 13:01:01.389]: rank: 0
[09/30 13:01:01.389]: local_rank: None
[09/30 13:01:01.389]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/30 13:01:11.213]: number of params:217230066
[09/30 13:01:11.216]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[09/30 13:11:03.515]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/30 13:11:03.515]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/30 13:11:03.517]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/30 13:11:03.517]: world size: 1
[09/30 13:11:03.517]: rank: 0
[09/30 13:11:03.517]: local_rank: None
[09/30 13:11:03.517]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/30 13:11:05.503]: number of params:46670782
[09/30 13:11:05.505]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/30 13:11:06.714]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/30 13:11:06.716]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/30 13:11:06.718]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/30 13:11:06.718]: world size: 1
[09/30 13:11:06.718]: rank: 0
[09/30 13:11:06.718]: local_rank: None
[09/30 13:11:06.718]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/30 13:11:08.397]: number of params:46670782
[09/30 13:11:08.399]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/30 17:27:23.717]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/30 17:27:23.735]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/30 17:27:23.736]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/30 17:27:23.737]: world size: 1
[09/30 17:27:23.737]: rank: 0
[09/30 17:27:23.737]: local_rank: None
[09/30 17:27:23.737]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/30 17:27:33.359]: number of params:46670782
[09/30 17:27:33.360]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/30 23:01:17.473]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/30 23:01:17.488]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/30 23:01:17.490]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/30 23:01:17.490]: world size: 1
[09/30 23:01:17.490]: rank: 0
[09/30 23:01:17.490]: local_rank: None
[09/30 23:01:17.490]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/30 23:01:24.665]: number of params:46670782
[09/30 23:01:24.666]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[09/30 23:45:23.759]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[09/30 23:45:23.760]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[09/30 23:45:23.762]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[09/30 23:45:23.763]: world size: 1
[09/30 23:45:23.763]: rank: 0
[09/30 23:45:23.763]: local_rank: None
[09/30 23:45:23.763]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[09/30 23:45:32.993]: number of params:46670782
[09/30 23:45:32.994]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/01 10:05:35.864]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[10/01 10:05:35.875]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[10/01 10:05:35.877]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[10/01 10:05:35.877]: world size: 1
[10/01 10:05:35.877]: rank: 0
[10/01 10:05:35.877]: local_rank: None
[10/01 10:05:35.877]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[10/01 10:05:44.924]: number of params:46670782
[10/01 10:05:44.926]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/01 10:07:27.126]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[10/01 10:07:27.127]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[10/01 10:07:27.129]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[10/01 10:07:27.129]: world size: 1
[10/01 10:07:27.130]: rank: 0
[10/01 10:07:27.130]: local_rank: None
[10/01 10:07:27.130]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[10/01 10:07:35.473]: number of params:46670782
[10/01 10:07:35.475]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/01 10:13:00.206]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[10/01 10:13:00.213]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[10/01 10:13:00.207]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[10/01 10:13:00.214]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[10/01 10:13:00.210]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[10/01 10:13:00.211]: world size: 1
[10/01 10:13:00.211]: rank: 0
[10/01 10:13:00.218]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[10/01 10:13:00.211]: local_rank: None
[10/01 10:13:00.219]: world size: 1
[10/01 10:13:00.213]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[10/01 10:13:00.220]: rank: 0
[10/01 10:13:00.222]: local_rank: None
[10/01 10:13:00.222]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[10/01 10:13:07.337]: number of params:46670782
[10/01 10:13:07.339]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/01 10:13:07.347]: number of params:46670782
[10/01 10:13:07.350]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/01 11:16:57.249]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[10/01 11:16:57.250]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack untargeted --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[10/01 11:16:57.252]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[10/01 11:16:57.252]: world size: 1
[10/01 11:16:57.252]: rank: 0
[10/01 11:16:57.252]: local_rank: None
[10/01 11:16:57.252]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[10/01 11:16:58.647]: number of params:46670782
[10/01 11:16:58.649]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/01 11:17:15.227]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[10/01 11:17:15.228]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[10/01 11:17:15.229]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[10/01 11:17:15.230]: world size: 1
[10/01 11:17:15.230]: rank: 0
[10/01 11:17:15.230]: local_rank: None
[10/01 11:17:15.230]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[10/01 11:17:16.587]: number of params:46670782
[10/01 11:17:16.589]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/01 21:25:27.197]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[10/01 21:25:27.209]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --attack_mode vanished --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[10/01 21:25:27.211]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[10/01 21:25:27.211]: world size: 1
[10/01 21:25:27.211]: rank: 0
[10/01 21:25:27.211]: local_rank: None
[10/01 21:25:27.211]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', attack_mode='vanished', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[10/01 21:25:36.779]: number of params:46670782
[10/01 21:25:36.780]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/01 21:27:31.666]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[10/01 21:27:31.666]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --attack_mode vanishing --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[10/01 21:27:31.667]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[10/01 21:27:31.667]: world size: 1
[10/01 21:27:31.668]: rank: 0
[10/01 21:27:31.668]: local_rank: None
[10/01 21:27:31.668]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', attack_mode='vanishing', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[10/01 21:27:32.910]: number of params:46670782
[10/01 21:27:32.911]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/01 21:29:01.897]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[10/01 21:29:01.898]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack attention --attack_mode vanishing --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[10/01 21:29:01.899]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[10/01 21:29:01.899]: world size: 1
[10/01 21:29:01.899]: rank: 0
[10/01 21:29:01.899]: local_rank: None
[10/01 21:29:01.900]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='attention', attack_mode='vanishing', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[10/01 21:29:03.142]: number of params:46670782
[10/01 21:29:03.144]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/01 21:31:03.947]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[10/01 21:31:03.949]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack untargeted --attack_mode vanishing --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[10/01 21:31:03.951]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[10/01 21:31:03.951]: world size: 1
[10/01 21:31:03.951]: rank: 0
[10/01 21:31:03.951]: local_rank: None
[10/01 21:31:03.951]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', attack_mode='vanishing', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[10/01 21:31:11.498]: number of params:46670782
[10/01 21:31:11.500]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/01 21:32:02.429]: git:
  sha: cf47c9dbe7f55accbddcc86ca796cff0b6238622, status: has uncommited changes, branch: main

[10/01 21:32:02.429]: Command: attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c dino_utils/config/DINO/DINO_4scale.py --num_workers 8 --coco_path dataset/coco --eval --resume model_files/checkpoint0011_4scale.pth --attack untargeted --attack_mode vanishing --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[10/01 21:32:02.431]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[10/01 21:32:02.431]: world size: 1
[10/01 21:32:02.431]: rank: 0
[10/01 21:32:02.431]: local_rank: None
[10/01 21:32:02.431]: args: Namespace(config_file='dino_utils/config/DINO/DINO_4scale.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='dataset/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='untargeted', attack_mode='vanishing', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[10/01 21:32:03.678]: number of params:46670782
[10/01 21:32:03.680]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
