[11/13 11:38:42.725]: git:
  sha: d3ae23cb5f16ab90e3d000983cc905d904ff6a0e, status: has uncommited changes, branch: main

[11/13 11:38:42.726]: Command: scripts/attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c utils/dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path datasets/mini_coco/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack afog --attack_mode baseline --sample_rate 1.0 --load_dir datasets/blackbox/internimage/ --load_attack 0.0 --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[11/13 11:38:42.728]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[11/13 11:38:42.728]: world size: 1
[11/13 11:38:42.728]: rank: 0
[11/13 11:38:42.728]: local_rank: None
[11/13 11:38:42.728]: args: Namespace(config_file='utils/dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='datasets/mini_coco/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='afog', attack_mode='baseline', sample_rate=1.0, load_dir='datasets/blackbox/internimage/', load_attack='0.0', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[11/13 11:44:49.381]: git:
  sha: d3ae23cb5f16ab90e3d000983cc905d904ff6a0e, status: has uncommited changes, branch: main

[11/13 11:44:49.382]: Command: scripts/attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c utils/dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path datasets/mini_coco/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack afog --attack_mode baseline --sample_rate 1.0 --load_dir datasets/blackbox/internimage/ --load_attack 0.0 --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[11/13 11:44:49.383]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[11/13 11:44:49.383]: world size: 1
[11/13 11:44:49.383]: rank: 0
[11/13 11:44:49.383]: local_rank: None
[11/13 11:44:49.384]: args: Namespace(config_file='utils/dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='datasets/mini_coco/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='afog', attack_mode='baseline', sample_rate=1.0, load_dir='datasets/blackbox/internimage/', load_attack='0.0', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[11/13 12:00:36.652]: git:
  sha: d3ae23cb5f16ab90e3d000983cc905d904ff6a0e, status: has uncommited changes, branch: main

[11/13 12:00:36.653]: Command: scripts/attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c utils/dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path datasets/mini_coco/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack afog --attack_mode baseline --sample_rate 1.0 --load_dir datasets/blackbox/internimage/ --load_attack 0.0 --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[11/13 12:00:36.656]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[11/13 12:00:36.656]: world size: 1
[11/13 12:00:36.656]: rank: 0
[11/13 12:00:36.656]: local_rank: None
[11/13 12:00:36.656]: args: Namespace(config_file='utils/dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='datasets/mini_coco/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='afog', attack_mode='baseline', sample_rate=1.0, load_dir='datasets/blackbox/internimage/', load_attack='0.0', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[11/13 12:00:52.949]: number of params:217230066
[11/13 12:00:52.952]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
[11/13 12:24:09.755]: git:
  sha: d3ae23cb5f16ab90e3d000983cc905d904ff6a0e, status: has uncommited changes, branch: main

[11/13 12:24:09.757]: Command: scripts/attack_dino.py --output_dir logs/DINO/R50-MS4-%j -c utils/dino_utils/config/DINO/DINO_4scale_swin.py --num_workers 8 --coco_path datasets/mini_coco/coco --eval --resume model_files/checkpoint0011_4scale_swin.pth --attack afog --attack_mode baseline --sample_rate 1.0 --load_dir datasets/blackbox/internimage/ --load_attack 0.0 --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0
[11/13 12:24:09.759]: Full config saved to logs/DINO/R50-MS4-%j/config_args_all.json
[11/13 12:24:09.759]: world size: 1
[11/13 12:24:09.759]: rank: 0
[11/13 12:24:09.759]: local_rank: None
[11/13 12:24:09.759]: args: Namespace(config_file='utils/dino_utils/config/DINO/DINO_4scale_swin.py', options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0}, dataset_file='coco', coco_path='datasets/mini_coco/coco', coco_panoptic_path=None, remove_difficult=False, fix_size=False, output_dir='logs/DINO/R50-MS4-%j', note='', device='cuda', seed=42, resume='model_files/checkpoint0011_4scale_swin.pth', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=True, num_workers=8, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=None, amp=False, attack='afog', attack_mode='baseline', sample_rate=1.0, load_dir='datasets/blackbox/internimage/', load_attack='0.0', data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=91, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=12, lr_drop=11, save_checkpoint_interval=1, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='dino', frozen_weights=None, backbone='swin_L_384_22k', use_checkpoint=True, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, unic_layers=0, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, random_refpoints_xy=False, fix_refpoints_hw=-1, dabdetr_yolo_like_anchor_update=False, dabdetr_deformable_encoder=False, dabdetr_deformable_decoder=False, use_deformable_box_attn=False, box_attn_type='roi_align', dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, decoder_layer_noise=False, dln_xy_noise=0.2, dln_hw_noise=0.2, add_channel_attention=False, add_pos_value=False, two_stage_type='standard', two_stage_pat_embed=0, two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, num_select=300, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, cls_loss_coef=1.0, mask_loss_coef=1.0, dice_loss_coef=1.0, bbox_loss_coef=5.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, use_dn=True, dn_number=100, dn_box_noise_scale=1.0, dn_label_noise_ratio=0.5, embed_init_tgt=True, dn_labelbook_size=91, match_unstable_error=True, use_ema=False, ema_decay=0.9997, ema_epoch=0, use_detached_boxes_dec_out=False, dn_scalar=100, dn_label_coef=1.0, dn_bbox_coef=1.0)

[11/13 12:24:24.755]: number of params:217230066
[11/13 12:24:24.758]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 98304,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 196608,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 393216,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 3538944,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.patch_embed.proj.weight": 9216,
  "backbone.0.patch_embed.proj.bias": 192,
  "backbone.0.patch_embed.norm.weight": 192,
  "backbone.0.patch_embed.norm.bias": 192,
  "backbone.0.layers.0.blocks.0.norm1.weight": 192,
  "backbone.0.layers.0.blocks.0.norm1.bias": 192,
  "backbone.0.layers.0.blocks.0.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.0.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.0.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.0.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.0.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.0.norm2.weight": 192,
  "backbone.0.layers.0.blocks.0.norm2.bias": 192,
  "backbone.0.layers.0.blocks.0.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.0.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.0.mlp.fc2.bias": 192,
  "backbone.0.layers.0.blocks.1.norm1.weight": 192,
  "backbone.0.layers.0.blocks.1.norm1.bias": 192,
  "backbone.0.layers.0.blocks.1.attn.relative_position_bias_table": 3174,
  "backbone.0.layers.0.blocks.1.attn.qkv.weight": 110592,
  "backbone.0.layers.0.blocks.1.attn.qkv.bias": 576,
  "backbone.0.layers.0.blocks.1.attn.proj.weight": 36864,
  "backbone.0.layers.0.blocks.1.attn.proj.bias": 192,
  "backbone.0.layers.0.blocks.1.norm2.weight": 192,
  "backbone.0.layers.0.blocks.1.norm2.bias": 192,
  "backbone.0.layers.0.blocks.1.mlp.fc1.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc1.bias": 768,
  "backbone.0.layers.0.blocks.1.mlp.fc2.weight": 147456,
  "backbone.0.layers.0.blocks.1.mlp.fc2.bias": 192,
  "backbone.0.layers.0.downsample.reduction.weight": 294912,
  "backbone.0.layers.0.downsample.norm.weight": 768,
  "backbone.0.layers.0.downsample.norm.bias": 768,
  "backbone.0.layers.1.blocks.0.norm1.weight": 384,
  "backbone.0.layers.1.blocks.0.norm1.bias": 384,
  "backbone.0.layers.1.blocks.0.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.0.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.0.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.0.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.0.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.0.norm2.weight": 384,
  "backbone.0.layers.1.blocks.0.norm2.bias": 384,
  "backbone.0.layers.1.blocks.0.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.0.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.0.mlp.fc2.bias": 384,
  "backbone.0.layers.1.blocks.1.norm1.weight": 384,
  "backbone.0.layers.1.blocks.1.norm1.bias": 384,
  "backbone.0.layers.1.blocks.1.attn.relative_position_bias_table": 6348,
  "backbone.0.layers.1.blocks.1.attn.qkv.weight": 442368,
  "backbone.0.layers.1.blocks.1.attn.qkv.bias": 1152,
  "backbone.0.layers.1.blocks.1.attn.proj.weight": 147456,
  "backbone.0.layers.1.blocks.1.attn.proj.bias": 384,
  "backbone.0.layers.1.blocks.1.norm2.weight": 384,
  "backbone.0.layers.1.blocks.1.norm2.bias": 384,
  "backbone.0.layers.1.blocks.1.mlp.fc1.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc1.bias": 1536,
  "backbone.0.layers.1.blocks.1.mlp.fc2.weight": 589824,
  "backbone.0.layers.1.blocks.1.mlp.fc2.bias": 384,
  "backbone.0.layers.1.downsample.reduction.weight": 1179648,
  "backbone.0.layers.1.downsample.norm.weight": 1536,
  "backbone.0.layers.1.downsample.norm.bias": 1536,
  "backbone.0.layers.2.blocks.0.norm1.weight": 768,
  "backbone.0.layers.2.blocks.0.norm1.bias": 768,
  "backbone.0.layers.2.blocks.0.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.0.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.0.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.0.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.0.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.0.norm2.weight": 768,
  "backbone.0.layers.2.blocks.0.norm2.bias": 768,
  "backbone.0.layers.2.blocks.0.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.0.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.0.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.1.norm1.weight": 768,
  "backbone.0.layers.2.blocks.1.norm1.bias": 768,
  "backbone.0.layers.2.blocks.1.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.1.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.1.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.1.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.1.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.1.norm2.weight": 768,
  "backbone.0.layers.2.blocks.1.norm2.bias": 768,
  "backbone.0.layers.2.blocks.1.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.1.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.1.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.2.norm1.weight": 768,
  "backbone.0.layers.2.blocks.2.norm1.bias": 768,
  "backbone.0.layers.2.blocks.2.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.2.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.2.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.2.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.2.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.2.norm2.weight": 768,
  "backbone.0.layers.2.blocks.2.norm2.bias": 768,
  "backbone.0.layers.2.blocks.2.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.2.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.2.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.3.norm1.weight": 768,
  "backbone.0.layers.2.blocks.3.norm1.bias": 768,
  "backbone.0.layers.2.blocks.3.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.3.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.3.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.3.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.3.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.3.norm2.weight": 768,
  "backbone.0.layers.2.blocks.3.norm2.bias": 768,
  "backbone.0.layers.2.blocks.3.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.3.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.3.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.4.norm1.weight": 768,
  "backbone.0.layers.2.blocks.4.norm1.bias": 768,
  "backbone.0.layers.2.blocks.4.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.4.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.4.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.4.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.4.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.4.norm2.weight": 768,
  "backbone.0.layers.2.blocks.4.norm2.bias": 768,
  "backbone.0.layers.2.blocks.4.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.4.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.4.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.5.norm1.weight": 768,
  "backbone.0.layers.2.blocks.5.norm1.bias": 768,
  "backbone.0.layers.2.blocks.5.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.5.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.5.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.5.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.5.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.5.norm2.weight": 768,
  "backbone.0.layers.2.blocks.5.norm2.bias": 768,
  "backbone.0.layers.2.blocks.5.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.5.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.5.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.6.norm1.weight": 768,
  "backbone.0.layers.2.blocks.6.norm1.bias": 768,
  "backbone.0.layers.2.blocks.6.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.6.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.6.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.6.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.6.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.6.norm2.weight": 768,
  "backbone.0.layers.2.blocks.6.norm2.bias": 768,
  "backbone.0.layers.2.blocks.6.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.6.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.6.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.7.norm1.weight": 768,
  "backbone.0.layers.2.blocks.7.norm1.bias": 768,
  "backbone.0.layers.2.blocks.7.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.7.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.7.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.7.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.7.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.7.norm2.weight": 768,
  "backbone.0.layers.2.blocks.7.norm2.bias": 768,
  "backbone.0.layers.2.blocks.7.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.7.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.7.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.8.norm1.weight": 768,
  "backbone.0.layers.2.blocks.8.norm1.bias": 768,
  "backbone.0.layers.2.blocks.8.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.8.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.8.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.8.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.8.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.8.norm2.weight": 768,
  "backbone.0.layers.2.blocks.8.norm2.bias": 768,
  "backbone.0.layers.2.blocks.8.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.8.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.8.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.9.norm1.weight": 768,
  "backbone.0.layers.2.blocks.9.norm1.bias": 768,
  "backbone.0.layers.2.blocks.9.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.9.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.9.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.9.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.9.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.9.norm2.weight": 768,
  "backbone.0.layers.2.blocks.9.norm2.bias": 768,
  "backbone.0.layers.2.blocks.9.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.9.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.9.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.10.norm1.weight": 768,
  "backbone.0.layers.2.blocks.10.norm1.bias": 768,
  "backbone.0.layers.2.blocks.10.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.10.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.10.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.10.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.10.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.10.norm2.weight": 768,
  "backbone.0.layers.2.blocks.10.norm2.bias": 768,
  "backbone.0.layers.2.blocks.10.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.10.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.10.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.11.norm1.weight": 768,
  "backbone.0.layers.2.blocks.11.norm1.bias": 768,
  "backbone.0.layers.2.blocks.11.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.11.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.11.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.11.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.11.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.11.norm2.weight": 768,
  "backbone.0.layers.2.blocks.11.norm2.bias": 768,
  "backbone.0.layers.2.blocks.11.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.11.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.11.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.12.norm1.weight": 768,
  "backbone.0.layers.2.blocks.12.norm1.bias": 768,
  "backbone.0.layers.2.blocks.12.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.12.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.12.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.12.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.12.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.12.norm2.weight": 768,
  "backbone.0.layers.2.blocks.12.norm2.bias": 768,
  "backbone.0.layers.2.blocks.12.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.12.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.12.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.13.norm1.weight": 768,
  "backbone.0.layers.2.blocks.13.norm1.bias": 768,
  "backbone.0.layers.2.blocks.13.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.13.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.13.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.13.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.13.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.13.norm2.weight": 768,
  "backbone.0.layers.2.blocks.13.norm2.bias": 768,
  "backbone.0.layers.2.blocks.13.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.13.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.13.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.14.norm1.weight": 768,
  "backbone.0.layers.2.blocks.14.norm1.bias": 768,
  "backbone.0.layers.2.blocks.14.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.14.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.14.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.14.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.14.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.14.norm2.weight": 768,
  "backbone.0.layers.2.blocks.14.norm2.bias": 768,
  "backbone.0.layers.2.blocks.14.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.14.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.14.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.15.norm1.weight": 768,
  "backbone.0.layers.2.blocks.15.norm1.bias": 768,
  "backbone.0.layers.2.blocks.15.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.15.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.15.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.15.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.15.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.15.norm2.weight": 768,
  "backbone.0.layers.2.blocks.15.norm2.bias": 768,
  "backbone.0.layers.2.blocks.15.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.15.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.15.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.16.norm1.weight": 768,
  "backbone.0.layers.2.blocks.16.norm1.bias": 768,
  "backbone.0.layers.2.blocks.16.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.16.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.16.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.16.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.16.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.16.norm2.weight": 768,
  "backbone.0.layers.2.blocks.16.norm2.bias": 768,
  "backbone.0.layers.2.blocks.16.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.16.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.16.mlp.fc2.bias": 768,
  "backbone.0.layers.2.blocks.17.norm1.weight": 768,
  "backbone.0.layers.2.blocks.17.norm1.bias": 768,
  "backbone.0.layers.2.blocks.17.attn.relative_position_bias_table": 12696,
  "backbone.0.layers.2.blocks.17.attn.qkv.weight": 1769472,
  "backbone.0.layers.2.blocks.17.attn.qkv.bias": 2304,
  "backbone.0.layers.2.blocks.17.attn.proj.weight": 589824,
  "backbone.0.layers.2.blocks.17.attn.proj.bias": 768,
  "backbone.0.layers.2.blocks.17.norm2.weight": 768,
  "backbone.0.layers.2.blocks.17.norm2.bias": 768,
  "backbone.0.layers.2.blocks.17.mlp.fc1.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc1.bias": 3072,
  "backbone.0.layers.2.blocks.17.mlp.fc2.weight": 2359296,
  "backbone.0.layers.2.blocks.17.mlp.fc2.bias": 768,
  "backbone.0.layers.2.downsample.reduction.weight": 4718592,
  "backbone.0.layers.2.downsample.norm.weight": 3072,
  "backbone.0.layers.2.downsample.norm.bias": 3072,
  "backbone.0.layers.3.blocks.0.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.0.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.0.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.0.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.0.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.0.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.0.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.0.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.0.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.0.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.0.mlp.fc2.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm1.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm1.bias": 1536,
  "backbone.0.layers.3.blocks.1.attn.relative_position_bias_table": 25392,
  "backbone.0.layers.3.blocks.1.attn.qkv.weight": 7077888,
  "backbone.0.layers.3.blocks.1.attn.qkv.bias": 4608,
  "backbone.0.layers.3.blocks.1.attn.proj.weight": 2359296,
  "backbone.0.layers.3.blocks.1.attn.proj.bias": 1536,
  "backbone.0.layers.3.blocks.1.norm2.weight": 1536,
  "backbone.0.layers.3.blocks.1.norm2.bias": 1536,
  "backbone.0.layers.3.blocks.1.mlp.fc1.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc1.bias": 6144,
  "backbone.0.layers.3.blocks.1.mlp.fc2.weight": 9437184,
  "backbone.0.layers.3.blocks.1.mlp.fc2.bias": 1536,
  "backbone.0.norm1.weight": 384,
  "backbone.0.norm1.bias": 384,
  "backbone.0.norm2.weight": 768,
  "backbone.0.norm2.bias": 768,
  "backbone.0.norm3.weight": 1536,
  "backbone.0.norm3.bias": 1536
}
